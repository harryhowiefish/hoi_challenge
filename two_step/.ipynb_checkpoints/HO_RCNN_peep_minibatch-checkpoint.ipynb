{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "# from keras_retinanet.models.resnet import custom_objects\n",
    "from keras_retinanet.models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "# import keras_retinanet\n",
    "import keras_retinanet.bin.train\n",
    "from sklearn.utils import shuffle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_json('../train_data_simple.json')\n",
    "train_data = train_data.sort_index()\n",
    "retinanet_data = pd.read_json('retinanet_data.json')\n",
    "retinanet_data = retinanet_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26561, 7), (26561, 8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,retinanet_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = []\n",
    "image_name = []\n",
    "for id_ in range(len(train_data)):\n",
    "    image_name.append(os.path.join('/home/jovyan/projectdata/cht01/hico_20160224_det/images/train2015/',train_data['name'][id_]))\n",
    "    action_array = np.zeros(600)\n",
    "    for i in train_data.action_no[id_]:\n",
    "        action_array[i-1]=1\n",
    "    action_list.append(action_array)\n",
    "action_list = np.array(action_list)\n",
    "image_name = np.array(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_gt = [[item[0],item[2],item[1],item[3]] for item in train_data.human_bbox.tolist()]\n",
    "human_gt = np.array(human_gt)\n",
    "object_gt = [[item[0],item[2],item[1],item[3]] for item in train_data.object_bbox.tolist()]\n",
    "object_gt = np.array(object_gt)\n",
    "obj_label_gt = train_data.obj_id.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_input,obj_boxes,obj_classes,human_boxes\n",
    "obj_boxes,human_boxes,obj_classes=[],[],[]\n",
    "for id_ in range(len(train_data)):\n",
    "    obj_box = retinanet_data.obj_boxes_scale[id_]\n",
    "    obj_class = retinanet_data.obj_classes[id_]\n",
    "    human_box = retinanet_data.human_boxes_scale[id_]\n",
    "    obj_box = np.array(obj_box)\n",
    "    obj_class = np.array(obj_class)\n",
    "    human_box = np.array(human_box)\n",
    "    obj_boxes.append(obj_box)\n",
    "    obj_classes.append(obj_class)\n",
    "    human_boxes.append(human_box)\n",
    "obj_boxes = np.array(obj_boxes)\n",
    "obj_classes = np.array(obj_classes)\n",
    "human_boxes = np.array(human_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [image_name,human_boxes,obj_boxes,obj_classes]\n",
    "y_label = [action_list,human_gt,object_gt,obj_label_gt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_stream(ip):\n",
    "    human_boxes = ip[0]\n",
    "    human_boxes = human_boxes[0,:,:]\n",
    "    img_input = ip[1]\n",
    "    crop_size = tf.constant([400,400])\n",
    "    batch_inds = tf.zeros((tf.shape(human_boxes)[0],), dtype=tf.int32) \n",
    "    human_boxes_norm = human_boxes/[1200,800,1200,800]\n",
    "    human_boxes_norm = tf.stack([human_boxes_norm[:,1],human_boxes_norm[:,0],human_boxes_norm[:,3],human_boxes_norm[:,2]],axis=1)\n",
    "\n",
    "    result = tf.image.crop_and_resize(img_input,human_boxes_norm,batch_inds,crop_size)\n",
    "\n",
    "    result = (result-K.min(result))/255 \n",
    "    return [result,human_boxes_norm]\n",
    "    \n",
    "def obj_stream(ip):\n",
    "    obj_boxes = ip[0]\n",
    "    obj_boxes = obj_boxes[0,:,:]\n",
    "    img_input = ip[1]\n",
    "    crop_size = tf.constant([400,400])\n",
    "    batch_inds = tf.zeros((tf.shape(obj_boxes)[0],), dtype=tf.int32) \n",
    "    obj_boxes_norm = obj_boxes/[1200,800,1200,800]\n",
    "    obj_boxes_norm = tf.stack([obj_boxes_norm[:,1],obj_boxes_norm[:,0],obj_boxes_norm[:,3],obj_boxes_norm[:,2]],axis=1)\n",
    "    result = tf.image.crop_and_resize(img_input,obj_boxes_norm,batch_inds,crop_size)\n",
    "    result = (result-K.min(result))/255 \n",
    "\n",
    "    return [result,obj_boxes_norm]\n",
    "\n",
    "def human_object_pair(ip):\n",
    "    human_boxes=ip[0]\n",
    "    obj_boxes=ip[1]\n",
    "    human_boxes = human_boxes[0,:,:]\n",
    "    obj_boxes = obj_boxes[0,:,:]\n",
    "    human_boxes_norm=ip[2]\n",
    "    obj_boxes_norm=ip[3]\n",
    "    human_count =tf.shape(human_boxes)[0]\n",
    "    obj_count = tf.shape(obj_boxes)[0]\n",
    "    ho_pair=[]\n",
    "    xx = tf.expand_dims(human_boxes, -1)\n",
    "    xx = tf.tile(xx, tf.stack([1, 1, obj_count]))\n",
    "    yy = tf.expand_dims(obj_boxes, -1)\n",
    "    yy = tf.tile(yy, tf.stack([1, 1, human_count]))\n",
    "    yy = tf.transpose(yy, perm=[2, 1, 0])       \n",
    "    ho_pair = tf.stack([xx,yy],axis=1)\n",
    "    ho_pair = tf.transpose(ho_pair,perm=[0,3,1,2])\n",
    "    ho_pair = tf.reshape(ho_pair,shape=(-1,2,4))\n",
    "    ho_pair_norm=[]\n",
    "    xx_norm = tf.expand_dims(human_boxes_norm, -1)\n",
    "    xx_norm = tf.tile(xx_norm, tf.stack([1, 1, obj_count]))\n",
    "    yy_norm = tf.expand_dims(obj_boxes_norm, -1)\n",
    "    yy_norm = tf.tile(yy_norm, tf.stack([1, 1, human_count]))\n",
    "    yy_norm = tf.transpose(yy_norm, perm=[2, 1, 0])       \n",
    "    ho_pair_norm = tf.stack([xx_norm,yy_norm],axis=1)\n",
    "    ho_pair_norm = tf.transpose(ho_pair_norm,perm=[0,3,1,2])\n",
    "    ho_pair_norm = tf.reshape(ho_pair_norm,shape=(-1,2,4))\n",
    "    return ho_pair\n",
    "\n",
    "def attention_pattern(ho_pair):\n",
    "    pair_count = tf.shape(ho_pair)[0]\n",
    "    offset_height_h = tf.cast(ho_pair[:,0,1],tf.int32)\n",
    "    offset_width_h = tf.cast(ho_pair[:,0,0],tf.int32)\n",
    "    target_height_h = tf.cast(ho_pair[:,0,3],tf.int32) - offset_height_h \n",
    "    target_width_h = tf.cast(ho_pair[:,0,2],tf.int32) - offset_width_h\n",
    "    offset_height_o = tf.cast(ho_pair[:,1,1],tf.int32)\n",
    "    offset_width_o = tf.cast(ho_pair[:,1,0],tf.int32)\n",
    "    target_height_o = tf.cast(ho_pair[:,1,3],tf.int32) - offset_height_o\n",
    "    target_width_o = tf.cast(ho_pair[:,1,2],tf.int32) -offset_width_o\n",
    "    mask_base = tf.constant(1,shape=(800,1200,3),dtype=tf.float32)\n",
    "    i = tf.constant(0)\n",
    "    pair_mask = tf.TensorArray(dtype=tf.float32, size=pair_count)\n",
    "    def condition(i,pair_mask):\n",
    "        return i < pair_count\n",
    "    \n",
    "    def body(i,pair_mask):\n",
    "        top_bound = tf.reduce_min(tf.stack([offset_height_h[i],offset_height_o[i]]))\n",
    "        left_bound = tf.reduce_min(tf.stack([offset_width_h[i],offset_width_o[i]]))\n",
    "        bottom_bound = tf.reduce_max(tf.stack([offset_height_h[i]+target_height_h[i],offset_height_o[i]+target_height_o[i]]))\n",
    "        right_bound = tf.reduce_max(tf.stack([offset_width_h[i]+target_width_h[i],offset_width_o[i]+target_width_o[i]]))\n",
    "        mask_target_height = bottom_bound-top_bound\n",
    "        mask_target_width = right_bound-left_bound\n",
    "        mask_h = tf.image.crop_to_bounding_box(\n",
    "            mask_base,offset_height_h[i],offset_width_h[i],target_height_h[i],target_width_h[i])\n",
    "        mask_h = tf.image.pad_to_bounding_box(mask_h,offset_height_h[i]-top_bound,offset_width_h[i]-left_bound,mask_target_height,mask_target_width)\n",
    "        mask_h = tf.image.resize_image_with_crop_or_pad(mask_h,tf.shape(mask_base)[0],tf.shape(mask_base)[1])\n",
    "        mask_o = tf.image.crop_to_bounding_box(\n",
    "            mask_base,offset_height_o[i],offset_width_o[i],target_height_o[i],target_width_o[i])\n",
    "        mask_o = tf.image.pad_to_bounding_box(mask_o,offset_height_o[i]-top_bound,offset_width_o[i]-left_bound,mask_target_height,mask_target_width)\n",
    "        mask_o = tf.image.resize_image_with_crop_or_pad(mask_o,tf.shape(mask_base)[0],tf.shape(mask_base)[1])\n",
    "        mask_combine = [tf.reduce_mean(mask_h,axis=2),tf.reduce_mean(mask_o,axis=2),tf.constant(0,shape=(800,1200),dtype=tf.float32)]\n",
    "        mask_combine = tf.stack(mask_combine,axis =2)\n",
    "        mask_combine = tf.expand_dims(mask_combine,axis=0)\n",
    "        mask_combine = tf.image.resize_bilinear(mask_combine,[128,128])\n",
    "        mask_combine = tf.squeeze(mask_combine,axis=0)\n",
    "        pair_mask = pair_mask.write(i, mask_combine)\n",
    "        i = tf.add(i,1)\n",
    "        return [i, pair_mask]\n",
    "    n, pair_mask = tf.while_loop(condition, body, [i, pair_mask])\n",
    "    # get the final result\n",
    "    pair_mask_stack = pair_mask.stack()\n",
    "    return pair_mask_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = keras.layers.Input(shape=(None,None,3),name='img_input')\n",
    "obj_boxes = keras.layers.Input(shape=(None,4),name='obj_boxes')\n",
    "obj_classes = keras.layers.Input(shape=(None,),name='obj_classes')\n",
    "human_boxes = keras.layers.Input(shape=(None,4),name='human_boxes')\n",
    "\n",
    "human_subimage,human_boxes_norm = keras.layers.Lambda(human_stream)([human_boxes,img_input])\n",
    "\n",
    "obj_subimage,obj_boxes_norm = keras.layers.Lambda(obj_stream)([obj_boxes,img_input])\n",
    "\n",
    "ho_pair= keras.layers.Lambda(human_object_pair)([human_boxes,obj_boxes,human_boxes_norm,obj_boxes_norm])\n",
    "\n",
    "pair_mask_stack = keras.layers.Lambda(attention_pattern)(ho_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dim(ip):\n",
    "    human_subimage = ip[0]\n",
    "    object_subimage = ip[1]\n",
    "    pair_mask_stack = ip[2]\n",
    "    human_subimage_expand = tf.expand_dims(human_subimage,axis=0)\n",
    "    obj_subimage_expand = tf.expand_dims(obj_subimage,axis=0)\n",
    "    pair_mask_stack_expand = tf.expand_dims(pair_mask_stack,axis=0)\n",
    "    return [human_subimage_expand,obj_subimage_expand,pair_mask_stack_expand]\n",
    "def output_sum(score_600):\n",
    "    score_sum = tf.reduce_sum(score_600,axis=1)\n",
    "    return score_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_subimage_expand,obj_subimage_expand,pair_mask_stack_expand= keras.layers.Lambda(expand_dim)([human_subimage,obj_subimage,pair_mask_stack])\n",
    "# #human stream\n",
    "# h_conv1 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(human_subimage_expand)\n",
    "# h_pool1 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(h_conv1)\n",
    "# h_conv2 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(h_pool1)\n",
    "# h_pool2 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(h_conv2)\n",
    "# h_conv3 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(h_pool2)\n",
    "# h_pool3 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(h_conv3)\n",
    "# h_flat = keras.layers.TimeDistributed(keras.layers.Flatten())(h_pool3)\n",
    "# h_output = keras.layers.TimeDistributed(keras.layers.Dense(units=600,activation='sigmoid'))(h_flat)\n",
    "# #object stream\n",
    "# o_conv1 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(obj_subimage_expand)\n",
    "# o_pool1 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(o_conv1)\n",
    "# o_conv2 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(o_pool1)\n",
    "# o_pool2 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(o_conv2)\n",
    "# o_conv3 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(o_pool2)\n",
    "# o_pool3 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(o_conv3)\n",
    "# o_flat = keras.layers.TimeDistributed(keras.layers.Flatten())(o_pool3)\n",
    "# o_output = keras.layers.TimeDistributed(keras.layers.Dense(units=600,activation='sigmoid'))(o_flat)\n",
    "# #pairwise stream\n",
    "# p_conv1 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(pair_mask_stack_expand)\n",
    "# p_pool1 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(2,2)))(p_conv1)\n",
    "# p_conv2 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(p_pool1)\n",
    "# p_pool2 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(2,2)))(p_conv2)\n",
    "# p_conv3 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(p_pool2)\n",
    "# p_pool3 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(2,2)))(p_conv3)\n",
    "# p_flat = keras.layers.TimeDistributed(keras.layers.Flatten())(p_pool3)\n",
    "# p_output = keras.layers.TimeDistributed(keras.layers.Dense(units=600,activation='sigmoid'))(p_flat)\n",
    "\n",
    "# # score_sum = keras.layers.Add()([h_output_merge,o_output_merge,p_output_merge])\n",
    "# # score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)\n",
    "# score_sum = keras.layers.Add()([h_output,o_output,p_output])\n",
    "# score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_subimage_expand,obj_subimage_expand,pair_mask_stack_expand= keras.layers.Lambda(expand_dim)([human_subimage,obj_subimage,pair_mask_stack])\n",
    "#human stream\n",
    "h_conv1 = keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(human_subimage)\n",
    "h_pool1 = keras.layers.MaxPool2D(pool_size=(3,3))(h_conv1)\n",
    "h_conv2 = keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(h_pool1)\n",
    "h_pool2 = keras.layers.MaxPool2D(pool_size=(3,3))(h_conv2)\n",
    "h_conv3 = keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(h_pool2)\n",
    "h_pool3 = keras.layers.MaxPool2D(pool_size=(3,3))(h_conv3)\n",
    "h_flat = keras.layers.Flatten()(h_pool3)\n",
    "h_output = keras.layers.Dense(units=600,activation='sigmoid')(h_flat)\n",
    "#object stream\n",
    "o_conv1 = keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(obj_subimage)\n",
    "o_pool1 = keras.layers.MaxPool2D(pool_size=(3,3))(o_conv1)\n",
    "o_conv2 = keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(o_pool1)\n",
    "o_pool2 = keras.layers.MaxPool2D(pool_size=(3,3))(o_conv2)\n",
    "o_conv3 = keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(o_pool2)\n",
    "o_pool3 = keras.layers.MaxPool2D(pool_size=(3,3))(o_conv3)\n",
    "o_flat = keras.layers.Flatten()(o_pool3)\n",
    "o_output = keras.layers.Dense(units=600,activation='sigmoid')(o_flat)\n",
    "#pairwise stream\n",
    "p_conv1 = keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(pair_mask_stack)\n",
    "p_pool1 = keras.layers.MaxPool2D(pool_size=(2,2))(p_conv1)\n",
    "p_conv2 = keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(p_pool1)\n",
    "p_pool2 = keras.layers.MaxPool2D(pool_size=(2,2))(p_conv2)\n",
    "p_conv3 = keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(p_pool2)\n",
    "p_pool3 = keras.layers.MaxPool2D(pool_size=(2,2))(p_conv3)\n",
    "p_flat = keras.layers.Flatten()(p_pool3)\n",
    "p_output = keras.layers.Dense(units=600,activation='sigmoid')(p_flat)\n",
    "\n",
    "# score_sum = keras.layers.Add()([h_output_merge,o_output_merge,p_output_merge])\n",
    "# score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)\n",
    "score_sum = keras.layers.Add()([h_output,o_output,p_output])\n",
    "score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[img_input,human_boxes,obj_boxes],outputs=score_sum_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "human_boxes (InputLayer)        (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "img_input (InputLayer)          (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "obj_boxes (InputLayer)          (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 400, 400, 3) 0           human_boxes[0][0]                \n",
      "                                                                 img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               [(None, 400, 400, 3) 0           obj_boxes[0][0]                  \n",
      "                                                                 img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2, 4)         0           human_boxes[0][0]                \n",
      "                                                                 obj_boxes[0][0]                  \n",
      "                                                                 lambda_1[0][1]                   \n",
      "                                                                 lambda_2[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 3)  0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 400, 400, 16) 448         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 400, 400, 16) 448         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 16) 448         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 133, 133, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 133, 133, 16) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 16)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 133, 133, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 133, 133, 32) 4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 44, 44, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 44, 44, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 44, 44, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 44, 44, 64)   18496       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12544)        0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 12544)        0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 16384)        0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 600)          7527000     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 600)          7527000     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 600)          9831000     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 600)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 600)          360600      add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 25,316,352\n",
      "Trainable params: 25,316,352\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = [image_name,human_boxes,obj_boxes,obj_classes]  y_label = [action_list,human_gt,object_gt]\n",
    "# (x1, y1, x2, y2)\n",
    "def bb_intersection_over_union(boxA,boxB):\n",
    "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
    "\txA = max(boxA[0], boxB[0])\n",
    "\tyA = max(boxA[1], boxB[1])\n",
    "\txB = min(boxA[2], boxB[2])\n",
    "\tyB = min(boxA[3], boxB[3])\n",
    " \n",
    "\t# compute the area of intersection rectangle\n",
    "\tinterArea = (xB - xA + 1) * (yB - yA + 1)\n",
    " \n",
    "\t# compute the area of both the prediction and ground-truth\n",
    "\t# rectangles\n",
    "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    " \n",
    "\t# compute the intersection over union by taking the intersection\n",
    "\t# area and dividing it by the sum of prediction + ground-truth\n",
    "\t# areas - the interesection area\n",
    "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "\t# return the intersection over union value\n",
    "\treturn iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(x_train, y_label,batch_size=8):\n",
    "    img_stack = np.array([]).reshape(0,800,1200,3)\n",
    "    action_array_stack = np.array([]).reshape(0,600)\n",
    "    human_stack = np.array([]).reshape(0,1,4)\n",
    "    object_stack = np.array([]).reshape(0,1,4)\n",
    "    while True:\n",
    "        new_ind = shuffle(range(len(x_train[0])))\n",
    "        for i in new_ind:\n",
    "            if (x_train[1][i].any()) & (x_train[3][i].any()) &(y_label[3][i][0] in x_train[3][i]):\n",
    "                \n",
    "                human_iou_list = []\n",
    "                for k in x_train[1][0]:\n",
    "                    human_iou_list.append(bb_intersection_over_union(y_label[1][0],k))\n",
    "                object_iou_list = []\n",
    "                for j in x_train[2][0]:\n",
    "                    object_iou_list.append(bb_intersection_over_union(y_label[1][0],j))\n",
    "                ho_pair_h = x_train[1][0][np.argmax(human_iou_list)]\n",
    "                ho_pair_o = x_train[2][0][np.argmax((x_train[3][0]==y_label[3][0][0])*object_iou_list)]\n",
    "                ho_pair_h = np.expand_dims(ho_pair_h,axis=0)\n",
    "                ho_pair_h = np.expand_dims(ho_pair_h,axis=0)\n",
    "                ho_pair_o = np.expand_dims(ho_pair_o,axis=0)\n",
    "                ho_pair_o = np.expand_dims(ho_pair_o,axis=0)\n",
    "\n",
    "                \n",
    "                img = cv2.imread(x_train[0][i])\n",
    "                img = cv2.resize(img, (1200,800))\n",
    "                img = img/255\n",
    "                img = np.expand_dims(img,axis=0)\n",
    "                \n",
    "                img_stack = np.row_stack([img_stack,img])\n",
    "                action_array_stack = np.row_stack([action_array_stack,y_label[0][i]])\n",
    "                human_stack = np.row_stack([human_stack,ho_pair_h])\n",
    "                object_stack = np.row_stack([object_stack,ho_pair_o])\n",
    "                \n",
    "                if img_stack.shape[0]==batch_size:\n",
    "                    x_batch = [img_stack,human_stack,object_stack]\n",
    "                    y_batch = action_array_stack.copy()\n",
    "                    img_stack = np.array([]).reshape(0,800,1200,3)\n",
    "                    action_array_stack = np.array([]).reshape(0,600)\n",
    "                    human_stack = np.array([]).reshape(0,1,4)\n",
    "                    object_stack = np.array([]).reshape(0,1,4)\n",
    "                    yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = data_gen(x_train,y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b = next(gen)\n",
    "# a[0].shape,a[1].shape,a[2].shape,b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爆Train一發"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 102/3320 [..............................] - ETA: 40:27 - loss: 0.0404"
     ]
    }
   ],
   "source": [
    "model.fit_generator(gen,steps_per_epoch=int(26561/8),epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
