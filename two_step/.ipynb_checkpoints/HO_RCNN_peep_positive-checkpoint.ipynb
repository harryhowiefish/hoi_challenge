{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "# from keras_retinanet.models.resnet import custom_objects\n",
    "from keras_retinanet.models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "# import keras_retinanet\n",
    "import keras_retinanet.bin.train\n",
    "from sklearn.utils import shuffle \n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_json('../train_data_simple.json')\n",
    "train_data = train_data.sort_index()\n",
    "retinanet_data = pd.read_json('retinanet_data.json')\n",
    "retinanet_data = retinanet_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26561, 7), (26561, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,retinanet_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_boxes</th>\n",
       "      <th>human_boxes_scale</th>\n",
       "      <th>human_classes</th>\n",
       "      <th>human_scores</th>\n",
       "      <th>obj_boxes</th>\n",
       "      <th>obj_boxes_scale</th>\n",
       "      <th>obj_classes</th>\n",
       "      <th>obj_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[408.5285644531, 137.1702575684, 590.03033447...</td>\n",
       "      <td>[[217, 82, 314, 289], [189, 108, 388, 279], [2...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.24128636720000002, 0.2087177634, 0.35492742...</td>\n",
       "      <td>[[384.8578491211, 70.9428253174, 883.437683105...</td>\n",
       "      <td>[[205, 42, 471, 217], [217, 82, 314, 289], [16...</td>\n",
       "      <td>[3, 0, 3, 3, 3, 0, 0, 0, 3]</td>\n",
       "      <td>[0.2452710122, 0.24128636720000002, 0.49595344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[515.2573242188, 2.3874969482, 1107.571899414...</td>\n",
       "      <td>[[274, 1, 590, 126], [401, 0, 636, 140]]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[0.34479168060000004, 0.6770228148]</td>\n",
       "      <td>[[756.3471679688, 567.7899169922, 817.62744140...</td>\n",
       "      <td>[[403, 340, 436, 363], [405, 341, 436, 363], [...</td>\n",
       "      <td>[49, 51, 51, 39, 41, 39, 55, 53, 45, 41, 45, 7...</td>\n",
       "      <td>[0.2125296295, 0.235072419, 0.2925423980000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>[[274, 401], [1, 0], [590, 636], [126, 140]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[295.9039916992, 352.1661376953, 341.69757080...</td>\n",
       "      <td>[[147, 281, 170, 341], [0, 361, 15, 388], [0, ...</td>\n",
       "      <td>[9, 2, 2, 2, 2, 2, 2, 2, 2, 7, 5, 5, 5]</td>\n",
       "      <td>[0.45125731830000004, 0.2788699865, 0.64107280...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[939.8218383789, 401.7608642578, 984.80657958...</td>\n",
       "      <td>[[501, 214, 525, 277], [130, 203, 165, 311], [...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.6018131971, 0.2301999032, 0.3746683598, 0.9...</td>\n",
       "      <td>[[939.8218383789, 401.7608642578, 984.80657958...</td>\n",
       "      <td>[[501, 214, 525, 277], [130, 203, 165, 311], [...</td>\n",
       "      <td>[0, 0, 27, 0, 0, 0, 0]</td>\n",
       "      <td>[0.6018131971, 0.2301999032, 0.2251143306, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[192.0525970459, 291.7764892578, 370.51116943...</td>\n",
       "      <td>[[102, 155, 197, 265]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.9221789241]</td>\n",
       "      <td>[[321.814666748, 445.8058776855, 350.372467041...</td>\n",
       "      <td>[[171, 236, 186, 261], [532, 275, 554, 292], [...</td>\n",
       "      <td>[41, 67, 39, 0, 62, 59, 60, 60, 13, 60, 59]</td>\n",
       "      <td>[0.21376061440000002, 0.2884043753, 0.73071849...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         human_boxes  \\\n",
       "0  [[408.5285644531, 137.1702575684, 590.03033447...   \n",
       "1  [[515.2573242188, 2.3874969482, 1107.571899414...   \n",
       "2                                                 []   \n",
       "3  [[939.8218383789, 401.7608642578, 984.80657958...   \n",
       "4  [[192.0525970459, 291.7764892578, 370.51116943...   \n",
       "\n",
       "                                   human_boxes_scale       human_classes  \\\n",
       "0  [[217, 82, 314, 289], [189, 108, 388, 279], [2...        [0, 0, 0, 0]   \n",
       "1           [[274, 1, 590, 126], [401, 0, 636, 140]]              [0, 0]   \n",
       "2       [[274, 401], [1, 0], [590, 636], [126, 140]]                  []   \n",
       "3  [[501, 214, 525, 277], [130, 203, 165, 311], [...  [0, 0, 0, 0, 0, 0]   \n",
       "4                             [[102, 155, 197, 265]]                 [0]   \n",
       "\n",
       "                                        human_scores  \\\n",
       "0  [0.24128636720000002, 0.2087177634, 0.35492742...   \n",
       "1                [0.34479168060000004, 0.6770228148]   \n",
       "2                                                 []   \n",
       "3  [0.6018131971, 0.2301999032, 0.3746683598, 0.9...   \n",
       "4                                     [0.9221789241]   \n",
       "\n",
       "                                           obj_boxes  \\\n",
       "0  [[384.8578491211, 70.9428253174, 883.437683105...   \n",
       "1  [[756.3471679688, 567.7899169922, 817.62744140...   \n",
       "2  [[295.9039916992, 352.1661376953, 341.69757080...   \n",
       "3  [[939.8218383789, 401.7608642578, 984.80657958...   \n",
       "4  [[321.814666748, 445.8058776855, 350.372467041...   \n",
       "\n",
       "                                     obj_boxes_scale  \\\n",
       "0  [[205, 42, 471, 217], [217, 82, 314, 289], [16...   \n",
       "1  [[403, 340, 436, 363], [405, 341, 436, 363], [...   \n",
       "2  [[147, 281, 170, 341], [0, 361, 15, 388], [0, ...   \n",
       "3  [[501, 214, 525, 277], [130, 203, 165, 311], [...   \n",
       "4  [[171, 236, 186, 261], [532, 275, 554, 292], [...   \n",
       "\n",
       "                                         obj_classes  \\\n",
       "0                        [3, 0, 3, 3, 3, 0, 0, 0, 3]   \n",
       "1  [49, 51, 51, 39, 41, 39, 55, 53, 45, 41, 45, 7...   \n",
       "2            [9, 2, 2, 2, 2, 2, 2, 2, 2, 7, 5, 5, 5]   \n",
       "3                             [0, 0, 27, 0, 0, 0, 0]   \n",
       "4        [41, 67, 39, 0, 62, 59, 60, 60, 13, 60, 59]   \n",
       "\n",
       "                                          obj_scores  \n",
       "0  [0.2452710122, 0.24128636720000002, 0.49595344...  \n",
       "1  [0.2125296295, 0.235072419, 0.2925423980000000...  \n",
       "2  [0.45125731830000004, 0.2788699865, 0.64107280...  \n",
       "3  [0.6018131971, 0.2301999032, 0.2251143306, 0.3...  \n",
       "4  [0.21376061440000002, 0.2884043753, 0.73071849...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retinanet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = []\n",
    "image_name = []\n",
    "for id_ in range(len(train_data)):\n",
    "    image_name.append(os.path.join('/home/jovyan/projectdata/cht01/hico_20160224_det/images/train2015/',train_data['name'][id_]))\n",
    "    action_array = np.zeros(600)\n",
    "    for i in train_data.action_no[id_]:\n",
    "        action_array[i-1]=1\n",
    "    action_list.append(action_array)\n",
    "action_list = np.array(action_list)\n",
    "image_name = np.array(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_gt = [[item[0],item[2],item[1],item[3]] for item in train_data.human_bbox.tolist()]\n",
    "human_gt = np.array(human_gt)\n",
    "object_gt = [[item[0],item[2],item[1],item[3]] for item in train_data.object_bbox.tolist()]\n",
    "object_gt = np.array(object_gt)\n",
    "obj_label_gt = train_data.obj_id.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_input,obj_boxes,obj_classes,human_boxes\n",
    "obj_boxes,obj_boxes_scale,human_boxes,human_boxes_scale,obj_classes=[],[],[],[],[]\n",
    "for id_ in range(len(train_data)):\n",
    "    obj_box = retinanet_data.obj_boxes[id_]\n",
    "    obj_box_scale = retinanet_data.obj_boxes_scale[id_]\n",
    "    obj_class = retinanet_data.obj_classes[id_]\n",
    "    human_box = retinanet_data.human_boxes[id_]\n",
    "    human_box_scale = retinanet_data.human_boxes_scale[id_]\n",
    "\n",
    "    obj_box = np.array(obj_box)\n",
    "    obj_box_scale = np.array(obj_box_scale)\n",
    "    obj_class = np.array(obj_class)\n",
    "    human_box = np.array(human_box)\n",
    "    human_box_scale = np.array(human_box_scale)\n",
    "    \n",
    "    obj_boxes.append(obj_box)\n",
    "    obj_boxes_scale.append(obj_box_scale)\n",
    "    obj_classes.append(obj_class)\n",
    "    human_boxes.append(human_box)\n",
    "    human_boxes_scale.append(human_box_scale)\n",
    "    \n",
    "obj_boxes = np.array(obj_boxes)\n",
    "obj_boxes_scale = np.array(obj_boxes_scale)\n",
    "obj_classes = np.array(obj_classes)\n",
    "human_boxes = np.array(human_boxes)\n",
    "human_boxes_scale = np.array(human_boxes_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_train,image_name_val = sklearn.model_selection.train_test_split(image_name,test_size=0.05,random_state=42)\n",
    "\n",
    "human_boxes_train,human_boxes_val = sklearn.model_selection.train_test_split(human_boxes,test_size=0.05,random_state=42)\n",
    "\n",
    "human_boxes_scale_train,human_boxes_scale_val = sklearn.model_selection.train_test_split(human_boxes_scale,test_size=0.05,random_state=42)\n",
    "\n",
    "obj_boxes_train,obj_boxes_val = sklearn.model_selection.train_test_split(obj_boxes,test_size=0.05,random_state=42)\n",
    "\n",
    "obj_boxes_scale_train,obj_boxes_scale_val = sklearn.model_selection.train_test_split(obj_boxes_scale,test_size=0.05,random_state=42)\n",
    "\n",
    "obj_classes_train,obj_classes_val = sklearn.model_selection.train_test_split(obj_classes,test_size=0.05,random_state=42)\n",
    "\n",
    "action_list_train,action_list_val = sklearn.model_selection.train_test_split(action_list,test_size=0.05,random_state=42)\n",
    "\n",
    "human_gt_train,human_gt_val = sklearn.model_selection.train_test_split(human_gt,test_size=0.05,random_state=42)\n",
    "\n",
    "object_gt_train,object_gt_val = sklearn.model_selection.train_test_split(object_gt,test_size=0.05,random_state=42)\n",
    "\n",
    "obj_label_gt_train,obj_label_gt_val = sklearn.model_selection.train_test_split(obj_label_gt,test_size=0.05,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [image_name_train,human_boxes_train,human_boxes_scale_train,obj_boxes_train,obj_boxes_scale_train,obj_classes_train]\n",
    "\n",
    "x_val = [image_name_val,human_boxes_val,human_boxes_scale_val,obj_boxes_val,obj_boxes_scale_val,obj_classes_val]\n",
    "\n",
    "y_train = [action_list_train,human_gt_train,object_gt_train,obj_label_gt_train]\n",
    "\n",
    "y_val = [action_list_val,human_gt_val,object_gt_val,obj_label_gt_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_stream(ip):\n",
    "    human_boxes = ip[0]\n",
    "    human_boxes = human_boxes[0,:,:]\n",
    "    img_input = ip[1]\n",
    "    crop_size = K.tf.constant([400,400])\n",
    "    batch_inds = K.tf.zeros((K.tf.shape(human_boxes)[0],), dtype=K.tf.int32) \n",
    "    human_boxes_norm = human_boxes/[1200,800,1200,800]\n",
    "    human_boxes_norm = K.tf.stack([human_boxes_norm[:,1],human_boxes_norm[:,0],human_boxes_norm[:,3],human_boxes_norm[:,2]],axis=1)\n",
    "\n",
    "    result = K.tf.image.crop_and_resize(img_input,human_boxes_norm,batch_inds,crop_size)\n",
    "\n",
    "    result = (result-K.min(result))/255 \n",
    "    return [result,human_boxes_norm]\n",
    "    \n",
    "def obj_stream(ip):\n",
    "    obj_boxes = ip[0]\n",
    "    obj_boxes = obj_boxes[0,:,:]\n",
    "    img_input = ip[1]\n",
    "    crop_size = K.tf.constant([400,400])\n",
    "    batch_inds = K.tf.zeros((K.tf.shape(obj_boxes)[0],), dtype=K.tf.int32) \n",
    "    obj_boxes_norm = obj_boxes/[1200,800,1200,800]\n",
    "    obj_boxes_norm = K.tf.stack([obj_boxes_norm[:,1],obj_boxes_norm[:,0],obj_boxes_norm[:,3],obj_boxes_norm[:,2]],axis=1)\n",
    "    result = K.tf.image.crop_and_resize(img_input,obj_boxes_norm,batch_inds,crop_size)\n",
    "    result = (result-K.min(result))/255 \n",
    "\n",
    "    return [result,obj_boxes_norm]\n",
    "\n",
    "def human_object_pair(ip):\n",
    "    human_boxes=ip[0]\n",
    "    obj_boxes=ip[1]\n",
    "    human_boxes = human_boxes[0,:,:]\n",
    "    obj_boxes = obj_boxes[0,:,:]\n",
    "    human_boxes_norm=ip[2]\n",
    "    obj_boxes_norm=ip[3]\n",
    "    human_count =K.tf.shape(human_boxes)[0]\n",
    "    obj_count = K.tf.shape(obj_boxes)[0]\n",
    "    ho_pair=[]\n",
    "    xx = K.tf.expand_dims(human_boxes, -1)\n",
    "    xx = K.tf.tile(xx, K.tf.stack([1, 1, obj_count]))\n",
    "    yy = K.tf.expand_dims(obj_boxes, -1)\n",
    "    yy = K.tf.tile(yy, K.tf.stack([1, 1, human_count]))\n",
    "    yy = K.tf.transpose(yy, perm=[2, 1, 0])       \n",
    "    ho_pair = K.tf.stack([xx,yy],axis=1)\n",
    "    ho_pair = K.tf.transpose(ho_pair,perm=[0,3,1,2])\n",
    "    ho_pair = K.tf.reshape(ho_pair,shape=(-1,2,4))\n",
    "    ho_pair_norm=[]\n",
    "    xx_norm = K.tf.expand_dims(human_boxes_norm, -1)\n",
    "    xx_norm = K.tf.tile(xx_norm, K.tf.stack([1, 1, obj_count]))\n",
    "    yy_norm = K.tf.expand_dims(obj_boxes_norm, -1)\n",
    "    yy_norm = K.tf.tile(yy_norm, K.tf.stack([1, 1, human_count]))\n",
    "    yy_norm = K.tf.transpose(yy_norm, perm=[2, 1, 0])       \n",
    "    ho_pair_norm = K.tf.stack([xx_norm,yy_norm],axis=1)\n",
    "    ho_pair_norm = K.tf.transpose(ho_pair_norm,perm=[0,3,1,2])\n",
    "    ho_pair_norm = K.tf.reshape(ho_pair_norm,shape=(-1,2,4))\n",
    "    return ho_pair\n",
    "\n",
    "def attention_pattern(ho_pair):\n",
    "    pair_count = K.tf.shape(ho_pair)[0]\n",
    "    offset_height_h = K.tf.cast(ho_pair[:,0,1],K.tf.int32)\n",
    "    offset_width_h = K.tf.cast(ho_pair[:,0,0],K.tf.int32)\n",
    "    target_height_h = K.tf.cast(ho_pair[:,0,3],K.tf.int32) - offset_height_h \n",
    "    target_width_h = K.tf.cast(ho_pair[:,0,2],K.tf.int32) - offset_width_h\n",
    "    offset_height_o = K.tf.cast(ho_pair[:,1,1],K.tf.int32)\n",
    "    offset_width_o = K.tf.cast(ho_pair[:,1,0],K.tf.int32)\n",
    "    target_height_o = K.tf.cast(ho_pair[:,1,3],K.tf.int32) - offset_height_o\n",
    "    target_width_o = K.tf.cast(ho_pair[:,1,2],K.tf.int32) -offset_width_o\n",
    "    mask_base = K.tf.constant(1,shape=(800,1200,3),dtype=K.tf.float32)\n",
    "    i = K.tf.constant(0)\n",
    "    pair_mask = K.tf.TensorArray(dtype=K.tf.float32, size=pair_count)\n",
    "    def condition(i,pair_mask):\n",
    "        return i < pair_count\n",
    "    \n",
    "    def body(i,pair_mask):\n",
    "        top_bound = K.tf.reduce_min(K.tf.stack([offset_height_h[i],offset_height_o[i]]))\n",
    "        left_bound = K.tf.reduce_min(K.tf.stack([offset_width_h[i],offset_width_o[i]]))\n",
    "        bottom_bound = K.tf.reduce_max(K.tf.stack([offset_height_h[i]+target_height_h[i],offset_height_o[i]+target_height_o[i]]))\n",
    "        right_bound = K.tf.reduce_max(K.tf.stack([offset_width_h[i]+target_width_h[i],offset_width_o[i]+target_width_o[i]]))\n",
    "        mask_target_height = bottom_bound-top_bound\n",
    "        mask_target_width = right_bound-left_bound\n",
    "        mask_h = K.tf.image.crop_to_bounding_box(\n",
    "            mask_base,offset_height_h[i],offset_width_h[i],target_height_h[i],target_width_h[i])\n",
    "        mask_h = K.tf.image.pad_to_bounding_box(mask_h,offset_height_h[i]-top_bound,offset_width_h[i]-left_bound,mask_target_height,mask_target_width)\n",
    "        mask_h = K.tf.image.resize_image_with_crop_or_pad(mask_h,K.tf.shape(mask_base)[0],K.tf.shape(mask_base)[1])\n",
    "        mask_o = K.tf.image.crop_to_bounding_box(\n",
    "            mask_base,offset_height_o[i],offset_width_o[i],target_height_o[i],target_width_o[i])\n",
    "        mask_o = K.tf.image.pad_to_bounding_box(mask_o,offset_height_o[i]-top_bound,offset_width_o[i]-left_bound,mask_target_height,mask_target_width)\n",
    "        mask_o = K.tf.image.resize_image_with_crop_or_pad(mask_o,K.tf.shape(mask_base)[0],K.tf.shape(mask_base)[1])\n",
    "        mask_combine = [K.tf.reduce_mean(mask_h,axis=2),K.tf.reduce_mean(mask_o,axis=2),K.tf.constant(0,shape=(800,1200),dtype=K.tf.float32)]\n",
    "        mask_combine = K.tf.stack(mask_combine,axis =2)\n",
    "        mask_combine = K.tf.expand_dims(mask_combine,axis=0)\n",
    "        mask_combine = K.tf.image.resize_bilinear(mask_combine,[128,128])\n",
    "        mask_combine = K.tf.squeeze(mask_combine,axis=0)\n",
    "        pair_mask = pair_mask.write(i, mask_combine)\n",
    "        i = K.tf.add(i,1)\n",
    "        return [i, pair_mask]\n",
    "    n, pair_mask = K.tf.while_loop(condition, body, [i, pair_mask])\n",
    "    # get the final result\n",
    "    pair_mask_stack = pair_mask.stack()\n",
    "    return pair_mask_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = keras.layers.Input(shape=(None,None,3),name='img_input')\n",
    "obj_boxes = keras.layers.Input(shape=(None,4),name='obj_boxes')\n",
    "obj_classes = keras.layers.Input(shape=(None,),name='obj_classes')\n",
    "human_boxes = keras.layers.Input(shape=(None,4),name='human_boxes')\n",
    "\n",
    "human_subimage,human_boxes_norm = keras.layers.Lambda(human_stream)([human_boxes,img_input])\n",
    "\n",
    "obj_subimage,obj_boxes_norm = keras.layers.Lambda(obj_stream)([obj_boxes,img_input])\n",
    "\n",
    "ho_pair= keras.layers.Lambda(human_object_pair)([human_boxes,obj_boxes,human_boxes_norm,obj_boxes_norm])\n",
    "\n",
    "pair_mask_stack = keras.layers.Lambda(attention_pattern)(ho_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dim(ip):\n",
    "    human_subimage = ip[0]\n",
    "    object_subimage = ip[1]\n",
    "    pair_mask_stack = ip[2]\n",
    "    human_subimage_expand = K.tf.expand_dims(human_subimage,axis=0)\n",
    "    obj_subimage_expand = K.tf.expand_dims(obj_subimage,axis=0)\n",
    "    pair_mask_stack_expand = K.tf.expand_dims(pair_mask_stack,axis=0)\n",
    "    return [human_subimage_expand,obj_subimage_expand,pair_mask_stack_expand]\n",
    "def output_sum(score_600):\n",
    "    score_sum = K.tf.reduce_sum(score_600,axis=1)\n",
    "    return score_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_subimage_expand,obj_subimage_expand,pair_mask_stack_expand= keras.layers.Lambda(expand_dim)([human_subimage,obj_subimage,pair_mask_stack])\n",
    "# #human stream\n",
    "# h_conv1 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(human_subimage_expand)\n",
    "# h_pool1 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(h_conv1)\n",
    "# h_conv2 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(h_pool1)\n",
    "# h_pool2 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(h_conv2)\n",
    "# h_conv3 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(h_pool2)\n",
    "# h_pool3 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(h_conv3)\n",
    "# h_flat = keras.layers.TimeDistributed(keras.layers.Flatten())(h_pool3)\n",
    "# h_output = keras.layers.TimeDistributed(keras.layers.Dense(units=600,activation='sigmoid'))(h_flat)\n",
    "# #object stream\n",
    "# o_conv1 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(obj_subimage_expand)\n",
    "# o_pool1 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(o_conv1)\n",
    "# o_conv2 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(o_pool1)\n",
    "# o_pool2 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(o_conv2)\n",
    "# o_conv3 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(o_pool2)\n",
    "# o_pool3 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(o_conv3)\n",
    "# o_flat = keras.layers.TimeDistributed(keras.layers.Flatten())(o_pool3)\n",
    "# o_output = keras.layers.TimeDistributed(keras.layers.Dense(units=600,activation='sigmoid'))(o_flat)\n",
    "# #pairwise stream\n",
    "# p_conv1 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(pair_mask_stack_expand)\n",
    "# p_pool1 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(2,2)))(p_conv1)\n",
    "# p_conv2 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(p_pool1)\n",
    "# p_pool2 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(2,2)))(p_conv2)\n",
    "# p_conv3 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(p_pool2)\n",
    "# p_pool3 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(2,2)))(p_conv3)\n",
    "# p_flat = keras.layers.TimeDistributed(keras.layers.Flatten())(p_pool3)\n",
    "# p_output = keras.layers.TimeDistributed(keras.layers.Dense(units=600,activation='sigmoid'))(p_flat)\n",
    "\n",
    "# # score_sum = keras.layers.Add()([h_output_merge,o_output_merge,p_output_merge])\n",
    "# # score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)\n",
    "# score_sum = keras.layers.Add()([h_output,o_output,p_output])\n",
    "# score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_subimage_expand,obj_subimage_expand,pair_mask_stack_expand= keras.layers.Lambda(expand_dim)([human_subimage,obj_subimage,pair_mask_stack])\n",
    "#human stream\n",
    "h_conv1 = keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(human_subimage)\n",
    "h_pool1 = keras.layers.MaxPool2D(pool_size=(3,3))(h_conv1)\n",
    "h_conv2 = keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(h_pool1)\n",
    "h_pool2 = keras.layers.MaxPool2D(pool_size=(3,3))(h_conv2)\n",
    "h_conv3 = keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(h_pool2)\n",
    "h_pool3 = keras.layers.MaxPool2D(pool_size=(3,3))(h_conv3)\n",
    "h_flat = keras.layers.Flatten()(h_pool3)\n",
    "h_output = keras.layers.Dense(units=600,activation='sigmoid')(h_flat)\n",
    "#object stream\n",
    "o_conv1 = keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(obj_subimage)\n",
    "o_pool1 = keras.layers.MaxPool2D(pool_size=(3,3))(o_conv1)\n",
    "o_conv2 = keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(o_pool1)\n",
    "o_pool2 = keras.layers.MaxPool2D(pool_size=(3,3))(o_conv2)\n",
    "o_conv3 = keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(o_pool2)\n",
    "o_pool3 = keras.layers.MaxPool2D(pool_size=(3,3))(o_conv3)\n",
    "o_flat = keras.layers.Flatten()(o_pool3)\n",
    "o_output = keras.layers.Dense(units=600,activation='sigmoid')(o_flat)\n",
    "#pairwise stream\n",
    "p_conv1 = keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(pair_mask_stack)\n",
    "p_pool1 = keras.layers.MaxPool2D(pool_size=(2,2))(p_conv1)\n",
    "p_conv2 = keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(p_pool1)\n",
    "p_pool2 = keras.layers.MaxPool2D(pool_size=(2,2))(p_conv2)\n",
    "p_conv3 = keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(p_pool2)\n",
    "p_pool3 = keras.layers.MaxPool2D(pool_size=(2,2))(p_conv3)\n",
    "p_flat = keras.layers.Flatten()(p_pool3)\n",
    "p_output = keras.layers.Dense(units=600,activation='sigmoid')(p_flat)\n",
    "\n",
    "# score_sum = keras.layers.Add()([h_output_merge,o_output_merge,p_output_merge])\n",
    "# score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)\n",
    "score_sum = keras.layers.Add()([h_output,o_output,p_output])\n",
    "score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[img_input,human_boxes,obj_boxes,obj_classes],outputs=[score_sum_sigmoid,obj_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "human_boxes (InputLayer)        (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "img_input (InputLayer)          (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "obj_boxes (InputLayer)          (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 400, 400, 3) 0           human_boxes[0][0]                \n",
      "                                                                 img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               [(None, 400, 400, 3) 0           obj_boxes[0][0]                  \n",
      "                                                                 img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2, 4)         0           human_boxes[0][0]                \n",
      "                                                                 obj_boxes[0][0]                  \n",
      "                                                                 lambda_1[0][1]                   \n",
      "                                                                 lambda_2[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 3)  0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 400, 400, 16) 448         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 400, 400, 16) 448         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 16) 448         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 133, 133, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 133, 133, 16) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 16)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 133, 133, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 133, 133, 32) 4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 44, 44, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 44, 44, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 44, 44, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 44, 44, 64)   18496       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12544)        0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 12544)        0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 16384)        0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 600)          7527000     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 600)          7527000     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 600)          9831000     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 600)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 600)          360600      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "obj_classes (InputLayer)        (None, None)         0                                            \n",
      "==================================================================================================\n",
      "Total params: 25,316,352\n",
      "Trainable params: 25,316,352\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    y_true = y_true[0]\n",
    "    y_pred = y_pred[0]\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "# def binary_accuracy(y_true, y_pred):\n",
    "#     y_true = y_true[0]\n",
    "#     y_pred = y_pred[0]\n",
    "#     return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss=custom_loss,\n",
    "              optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = [image_name,human_boxes,obj_boxes,obj_classes]  y_label = [action_list,human_gt,object_gt]\n",
    "# (x1, y1, x2, y2)\n",
    "def bb_intersection_over_union(boxA,boxB):\n",
    "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
    "\txA = max(boxA[0], boxB[0])\n",
    "\tyA = max(boxA[1], boxB[1])\n",
    "\txB = min(boxA[2], boxB[2])\n",
    "\tyB = min(boxA[3], boxB[3])\n",
    " \n",
    "\t# compute the area of intersection rectangle\n",
    "\tinterArea = (xB - xA + 1) * (yB - yA + 1)\n",
    " \n",
    "\t# compute the area of both the prediction and ground-truth\n",
    "\t# rectangles\n",
    "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    " \n",
    "\t# compute the intersection over union by taking the intersection\n",
    "\t# area and dividing it by the sum of prediction + ground-truth\n",
    "\t# areas - the interesection area\n",
    "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "\t# return the intersection over union value\n",
    "\treturn iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = [image_name_train, human_boxes_train, human_boxes_scale_train, obj_boxes_train, obj_boxes_scale_train, obj_classes_train]\n",
    "# x_val = [image_name_val,human_boxes_val,human_boxes_scale_val,obj_boxes_val,obj_boxes_scale_val,obj_classes_val]\n",
    "# y_train = [action_list_train, human_gt_train, object_gt_train, obj_label_gt_train]\n",
    "# y_val = [action_list_val,human_gt_val,object_gt_val,obj_label_gt_val]\n",
    "def data_gen(x_train, y_label,batch_size=8):\n",
    "    img_stack = np.array([]).reshape(0,800,1200,3)\n",
    "    action_array_stack = np.array([]).reshape(0,600)\n",
    "    human_stack = np.array([]).reshape(0,1,4)\n",
    "    object_stack = np.array([]).reshape(0,1,4)\n",
    "    object_class_stack = np.array([]).reshape(0,1)\n",
    "    while True:\n",
    "        new_ind = shuffle(range(len(x_train[0])))\n",
    "        for i in new_ind:\n",
    "            if (x_train[1][i].any()) & (x_train[3][i].any()) &(y_label[3][i][0] in x_train[5][i]):\n",
    "                \n",
    "                human_iou_list = []\n",
    "                for k in x_train[2][i]:\n",
    "                    human_iou_list.append(bb_intersection_over_union(y_label[1][i],k))\n",
    "                object_iou_list = []\n",
    "                for j in x_train[4][i]:\n",
    "                    object_iou_list.append(bb_intersection_over_union(y_label[1][i],j))\n",
    "                \n",
    "                ho_pair_h = x_train[1][i][np.argmax(human_iou_list)]\n",
    "                ho_pair_o = x_train[3][i][np.argmax((x_train[5][i]==y_label[3][i][0])*object_iou_list)]\n",
    "                ho_pair_h = np.expand_dims(ho_pair_h,axis=0)\n",
    "                ho_pair_h = np.expand_dims(ho_pair_h,axis=0)\n",
    "                ho_pair_o = np.expand_dims(ho_pair_o,axis=0)\n",
    "                ho_pair_o = np.expand_dims(ho_pair_o,axis=0)\n",
    "\n",
    "                object_class = x_train[5][i][np.argmax((x_train[5][i]==y_label[3][i][0])*object_iou_list)]\n",
    "                object_class = np.expand_dims(object_class,axis=0)\n",
    "                \n",
    "                img = cv2.imread(x_train[0][i])\n",
    "                img = cv2.resize(img, (1200,800))\n",
    "                img = img/255\n",
    "                img = np.expand_dims(img,axis=0)\n",
    "                \n",
    "                \n",
    "                \n",
    "                img_stack = np.row_stack([img_stack,img])\n",
    "                action_array_stack = np.row_stack([action_array_stack,y_label[0][i]])\n",
    "                human_stack = np.row_stack([human_stack,ho_pair_h])\n",
    "                object_stack = np.row_stack([object_stack,ho_pair_o])\n",
    "                object_class_stack = np.row_stack([object_class_stack,object_class])\n",
    "                \n",
    "                if img_stack.shape[0]==batch_size:\n",
    "                    x_batch = [img_stack,human_stack,object_stack,object_class_stack]\n",
    "                    y_batch = [action_array_stack,object_class_stack]\n",
    "                    img_stack = np.array([]).reshape(0,800,1200,3)\n",
    "                    action_array_stack = np.array([]).reshape(0,600)\n",
    "                    human_stack = np.array([]).reshape(0,1,4)\n",
    "                    object_stack = np.array([]).reshape(0,1,4)\n",
    "                    object_class_stack = np.array([]).reshape(0,1)\n",
    "\n",
    "                    yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_gen(x_train,y_train)\n",
    "val_gen = data_gen(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25232, 1329)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0]),len(x_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b = next(val_gen)\n",
    "# a[0].shape,a[1].shape,a[2].shape,b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爆Train一發"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [16384,600] and type float\n\t [[Node: training/Adam/zeros_22 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [16384,600] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'training/Adam/zeros_22', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-39-006f14eff20b>\", line 1, in <module>\n    model.fit_generator(train_gen,steps_per_epoch=50,epochs=1,validation_data=val_gen,validation_steps=1)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\", line 2026, in fit_generator\n    self._make_train_function()\n  File \"/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/optimizers.py\", line 446, in get_updates\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/conda/lib/python3.6/site-packages/keras/optimizers.py\", line 446, in <listcomp>\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 689, in zeros\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1439, in zeros\n    output = constant(zero, shape=shape, dtype=dtype, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 214, in constant\n    name=name).outputs[0]\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [16384,600] and type float\n\t [[Node: training/Adam/zeros_22 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [16384,600] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [16384,600] and type float\n\t [[Node: training/Adam/zeros_22 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [16384,600] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-006f14eff20b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1849\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2475\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [16384,600] and type float\n\t [[Node: training/Adam/zeros_22 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [16384,600] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'training/Adam/zeros_22', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-39-006f14eff20b>\", line 1, in <module>\n    model.fit_generator(train_gen,steps_per_epoch=50,epochs=1,validation_data=val_gen,validation_steps=1)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\", line 2026, in fit_generator\n    self._make_train_function()\n  File \"/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/optimizers.py\", line 446, in get_updates\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/conda/lib/python3.6/site-packages/keras/optimizers.py\", line 446, in <listcomp>\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 689, in zeros\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1439, in zeros\n    output = constant(zero, shape=shape, dtype=dtype, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 214, in constant\n    name=name).outputs[0]\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [16384,600] and type float\n\t [[Node: training/Adam/zeros_22 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [16384,600] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_gen,steps_per_epoch=50,epochs=1,validation_data=val_gen,validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"/home/jovyan/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('/home/jovyan/hico_first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/jovyan/hico_first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_gen = data_gen(x_train,y_train,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = next(visualize_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed launch CropAndResizeKernel.\n\t [[Node: lambda_1/CropAndResize = CropAndResize[T=DT_FLOAT, extrapolation_value=0, method=\"bilinear\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_img_input_0_1/_183, lambda_1/stack, lambda_1/zeros/_185, lambda_1/Const)]]\n\t [[Node: lambda_4/while/GreaterEqual_24/_483 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_844_lambda_4/while/GreaterEqual_24\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_clooplambda_4/while/Assert_17/Assert/data_0/_169)]]\n\nCaused by op 'lambda_1/CropAndResize', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-a9c2f41a993d>\", line 6, in <module>\n    human_subimage,human_boxes_norm = keras.layers.Lambda(human_stream)([human_boxes,img_input])\n  File \"/opt/conda/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/layers/core.py\", line 663, in call\n    return self.function(inputs, **arguments)\n  File \"<ipython-input-13-031f18d3a727>\", line 10, in human_stream\n    result = K.tf.image.crop_and_resize(img_input,human_boxes_norm,batch_inds,crop_size)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_image_ops.py\", line 237, in crop_and_resize\n    extrapolation_value=extrapolation_value, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Failed launch CropAndResizeKernel.\n\t [[Node: lambda_1/CropAndResize = CropAndResize[T=DT_FLOAT, extrapolation_value=0, method=\"bilinear\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_img_input_0_1/_183, lambda_1/stack, lambda_1/zeros/_185, lambda_1/Const)]]\n\t [[Node: lambda_4/while/GreaterEqual_24/_483 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_844_lambda_4/while/GreaterEqual_24\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_clooplambda_4/while/Assert_17/Assert/data_0/_169)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed launch CropAndResizeKernel.\n\t [[Node: lambda_1/CropAndResize = CropAndResize[T=DT_FLOAT, extrapolation_value=0, method=\"bilinear\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_img_input_0_1/_183, lambda_1/stack, lambda_1/zeros/_185, lambda_1/Const)]]\n\t [[Node: lambda_4/while/GreaterEqual_24/_483 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_844_lambda_4/while/GreaterEqual_24\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_clooplambda_4/while/Assert_17/Assert/data_0/_169)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-b2b2a1739579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1910\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1912\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed launch CropAndResizeKernel.\n\t [[Node: lambda_1/CropAndResize = CropAndResize[T=DT_FLOAT, extrapolation_value=0, method=\"bilinear\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_img_input_0_1/_183, lambda_1/stack, lambda_1/zeros/_185, lambda_1/Const)]]\n\t [[Node: lambda_4/while/GreaterEqual_24/_483 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_844_lambda_4/while/GreaterEqual_24\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_clooplambda_4/while/Assert_17/Assert/data_0/_169)]]\n\nCaused by op 'lambda_1/CropAndResize', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-a9c2f41a993d>\", line 6, in <module>\n    human_subimage,human_boxes_norm = keras.layers.Lambda(human_stream)([human_boxes,img_input])\n  File \"/opt/conda/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/layers/core.py\", line 663, in call\n    return self.function(inputs, **arguments)\n  File \"<ipython-input-13-031f18d3a727>\", line 10, in human_stream\n    result = K.tf.image.crop_and_resize(img_input,human_boxes_norm,batch_inds,crop_size)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_image_ops.py\", line 237, in crop_and_resize\n    extrapolation_value=extrapolation_value, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Failed launch CropAndResizeKernel.\n\t [[Node: lambda_1/CropAndResize = CropAndResize[T=DT_FLOAT, extrapolation_value=0, method=\"bilinear\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_img_input_0_1/_183, lambda_1/stack, lambda_1/zeros/_185, lambda_1/Const)]]\n\t [[Node: lambda_4/while/GreaterEqual_24/_483 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_844_lambda_4/while/GreaterEqual_24\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_clooplambda_4/while/Assert_17/Assert/data_0/_169)]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_on_batch(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
