{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "# from keras_retinanet.models.resnet import custom_objects\n",
    "from keras_retinanet.models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "# import keras_retinanet\n",
    "import keras_retinanet.bin.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,512,512]\n\t [[Node: res5a_branch2b/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@res5a_branch2b/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res5a_branch2b/kernel, res5a_branch2b/truncated_normal)]]\n\nCaused by op 'res5a_branch2b/kernel/Assign', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-9c0de348e455>\", line 4, in <module>\n    multi_gpu=0, freeze_backbone=True)\n  File \"/opt/conda/lib/python3.6/site-packages/keras_retinanet/bin/train.py\", line 91, in create_models\n    model            = model_with_weights(backbone_retinanet(num_classes, backbone=backbone, nms=True, modifier=modifier), weights=weights, skip_mismatch=True)\n  File \"/opt/conda/lib/python3.6/site-packages/keras_retinanet/models/resnet.py\", line 69, in resnet_retinanet\n    resnet = keras_resnet.models.ResNet50(inputs, include_top=False, freeze_bn=True)\n  File \"/opt/conda/lib/python3.6/site-packages/keras_resnet/models/_2d.py\", line 188, in ResNet50\n    return ResNet(inputs, blocks, numerical_names=numerical_names, block=keras_resnet.blocks.bottleneck_2d, include_top=include_top, classes=classes, *args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/keras_resnet/models/_2d.py\", line 76, in ResNet\n    x = block(features, stage_id, block_id, numerical_name=(block_id > 0 and numerical_names[stage_id]), freeze_bn=freeze_bn)(x)\n  File \"/opt/conda/lib/python3.6/site-packages/keras_resnet/blocks/_2d.py\", line 134, in f\n    y = keras.layers.Conv2D(filters, kernel_size, use_bias=False, name=\"res{}{}_branch2b\".format(stage_char, block_char), **parameters)(y)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/engine/topology.py\", line 590, in __call__\n    self.build(input_shapes[0])\n  File \"/opt/conda/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 138, in build\n    constraint=self.kernel_constraint)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/engine/topology.py\", line 414, in add_weight\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 392, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,512,512]\n\t [[Node: res5a_branch2b/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@res5a_branch2b/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res5a_branch2b/kernel, res5a_branch2b/truncated_normal)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,512,512]\n\t [[Node: res5a_branch2b/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@res5a_branch2b/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res5a_branch2b/kernel, res5a_branch2b/truncated_normal)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9c0de348e455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#                                                    multi_gpu=0, freeze_backbone=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m retinanet_model, _,_=keras_retinanet.bin.train.create_models(retinanet, 'resnet50', 80, '/home/jovyan/keras-retinanet/snapshots/resnet50_coco_best_v2.0.2.h5', \n\u001b[0;32m----> 4\u001b[0;31m                                                    multi_gpu=0, freeze_backbone=True)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# retinanet_model = keras.models.load_model('/home/jovyan/keras-retinanet/snapshots/resnet50_coco_best_v2.0.2.h5', custom_objects=custom_objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras_retinanet/bin/train.py\u001b[0m in \u001b[0;36mcreate_models\u001b[0;34m(backbone_retinanet, backbone, num_classes, weights, multi_gpu, freeze_backbone)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mprediction_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mmodel\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mmodel_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone_retinanet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mtraining_model\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mprediction_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras_retinanet/bin/train.py\u001b[0m in \u001b[0;36mmodel_with_weights\u001b[0;34m(model, weights, skip_mismatch)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m             load_weights_from_hdf5_group_by_name(\n\u001b[0;32m-> 2643\u001b[0;31m                 f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[0m\u001b[1;32m   2644\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[0;34m(f, layers, skip_mismatch)\u001b[0m\n\u001b[1;32m   3246\u001b[0m                                             weight_values[i]))\n\u001b[1;32m   3247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3248\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2368\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2370\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,512,512]\n\t [[Node: res5a_branch2b/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@res5a_branch2b/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res5a_branch2b/kernel, res5a_branch2b/truncated_normal)]]\n\nCaused by op 'res5a_branch2b/kernel/Assign', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-9c0de348e455>\", line 4, in <module>\n    multi_gpu=0, freeze_backbone=True)\n  File \"/opt/conda/lib/python3.6/site-packages/keras_retinanet/bin/train.py\", line 91, in create_models\n    model            = model_with_weights(backbone_retinanet(num_classes, backbone=backbone, nms=True, modifier=modifier), weights=weights, skip_mismatch=True)\n  File \"/opt/conda/lib/python3.6/site-packages/keras_retinanet/models/resnet.py\", line 69, in resnet_retinanet\n    resnet = keras_resnet.models.ResNet50(inputs, include_top=False, freeze_bn=True)\n  File \"/opt/conda/lib/python3.6/site-packages/keras_resnet/models/_2d.py\", line 188, in ResNet50\n    return ResNet(inputs, blocks, numerical_names=numerical_names, block=keras_resnet.blocks.bottleneck_2d, include_top=include_top, classes=classes, *args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/keras_resnet/models/_2d.py\", line 76, in ResNet\n    x = block(features, stage_id, block_id, numerical_name=(block_id > 0 and numerical_names[stage_id]), freeze_bn=freeze_bn)(x)\n  File \"/opt/conda/lib/python3.6/site-packages/keras_resnet/blocks/_2d.py\", line 134, in f\n    y = keras.layers.Conv2D(filters, kernel_size, use_bias=False, name=\"res{}{}_branch2b\".format(stage_char, block_char), **parameters)(y)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/engine/topology.py\", line 590, in __call__\n    self.build(input_shapes[0])\n  File \"/opt/conda/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 138, in build\n    constraint=self.kernel_constraint)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/engine/topology.py\", line 414, in add_weight\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 392, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,512,512]\n\t [[Node: res5a_branch2b/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@res5a_branch2b/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res5a_branch2b/kernel, res5a_branch2b/truncated_normal)]]\n"
     ]
    }
   ],
   "source": [
    "# retinanet_model, _,_=keras_retinanet.bin.train.create_models(retinanet, 'resnet50', 80, 'resnet50_coco_best_v2.0.2.h5', \n",
    "#                                                    multi_gpu=0, freeze_backbone=True)\n",
    "retinanet_model, _,_=keras_retinanet.bin.train.create_models(retinanet, 'resnet50', 80, '/home/jovyan/keras-retinanet/snapshots/resnet50_coco_best_v2.0.2.h5', \n",
    "                                                   multi_gpu=0, freeze_backbone=True)\n",
    "# retinanet_model = keras.models.load_model('/home/jovyan/keras-retinanet/snapshots/resnet50_coco_best_v2.0.2.h5', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_bbox(ip,threshold = 0.2):\n",
    "    bbox = ip[0]\n",
    "    classification = ip[1]\n",
    "\n",
    "    predicted_labels = K.argmax(classification, axis=2)\n",
    "    scores = K.max(classification,axis=2)\n",
    "\n",
    "    filtering_mask = (scores >= threshold) & K.equal(predicted_labels,0)\n",
    "\n",
    "    scores = tf.boolean_mask(scores, filtering_mask) \n",
    "    boxes = tf.boolean_mask(bbox, filtering_mask) \n",
    "    classes = tf.boolean_mask(predicted_labels, filtering_mask) \n",
    "#     scores, boxes, classes = non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5)\n",
    "    return [scores, boxes, classes]\n",
    "\n",
    "def obj_bbox(ip,threshold = 0.2):\n",
    "    bbox = ip[0]\n",
    "    classification = ip[1]\n",
    "\n",
    "    predicted_labels = K.argmax(classification, axis=2)\n",
    "    scores = K.max(classification,axis=2)\n",
    "\n",
    "    filtering_mask = (scores >= threshold)\n",
    "\n",
    "    scores = tf.boolean_mask(scores, filtering_mask) \n",
    "    boxes = tf.boolean_mask(bbox, filtering_mask) \n",
    "    classes = tf.boolean_mask(predicted_labels, filtering_mask) \n",
    "#     scores, boxes, classes = non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5)\n",
    "    return [scores, boxes, classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = keras.layers.Input(shape=(None,None,3),name='img_input')\n",
    "\n",
    "_,_,bbox,classification=retinanet_model(img_input)\n",
    "\n",
    "human_scores, human_boxes, human_classes= keras.layers.Lambda(human_bbox)([bbox, classification])\n",
    "\n",
    "obj_scores, obj_boxes, obj_classes= keras.layers.Lambda(obj_bbox)([bbox, classification])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all = keras.Model(inputs=img_input,outputs=[obj_scores, obj_boxes, obj_classes,\n",
    "                                                 human_scores, human_boxes, human_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_simple = pd.read_json('../train_data_simple.json')\n",
    "train_data_simple = train_data_simple.sort_index()\n",
    "test_data = pd.read_json('../test_data.json')\n",
    "test_data = test_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_generator(id_):\n",
    "    target_width = 1200\n",
    "    target_height = 800\n",
    "    scale_width = target_width/train_data_simple['size'][id_][0]\n",
    "    scale_height = target_height/train_data_simple['size'][id_][1]\n",
    "    image = cv2.imread(os.path.join('/home/jovyan/projectdata/cht01/hico_20160224_det/images/train2015/',train_data_simple['name'][id_]))\n",
    "    image = cv2.resize(image,(target_width,target_height))\n",
    "    return np.expand_dims(image,axis=0)\n",
    "def test_data_generator(id_):\n",
    "    target_width = 1200\n",
    "    target_height = 800\n",
    "    scale_width = target_width/test_data['size'][id_][0]\n",
    "    scale_height = target_height/test_data['size'][id_][1]\n",
    "    image = cv2.imread(os.path.join('/home/jovyan/projectdata/cht01/hico_20160224_det/images/test2015/',test_data['name'][id_]))\n",
    "    image = cv2.resize(image,(target_width,target_height))\n",
    "    return np.expand_dims(image,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_obj_scores, pred_obj_boxes, pred_obj_classes,pred_human_scores, pred_human_boxes, pred_human_classes =[],[],[],[],[],[]\n",
    "for i in tqdm(range(len(train_data_simple))):\n",
    "    img = train_data_generator(i)\n",
    "    a,b,c,d,e,f = model_all.predict_on_batch(img)\n",
    "    pred_obj_scores.append(a)\n",
    "    pred_obj_boxes.append(b)\n",
    "    pred_obj_classes.append(c)\n",
    "    pred_human_scores.append(d)\n",
    "    pred_human_boxes.append(e)\n",
    "    pred_human_classes.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a181b5e87b438fa9b0510335450dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9658), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_obj_scores, test_obj_boxes, test_obj_classes,test_human_scores, test_human_boxes, test_human_classes =[],[],[],[],[],[]\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    img = test_data_generator(i)\n",
    "    a,b,c,d,e,f = model_all.predict_on_batch(img)\n",
    "    test_obj_scores.append(a)\n",
    "    test_obj_boxes.append(b)\n",
    "    test_obj_classes.append(c)\n",
    "    test_human_scores.append(d)\n",
    "    test_human_boxes.append(e)\n",
    "    test_human_classes.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet_train_data = pd.DataFrame({\n",
    "    'obj_scores':pred_obj_scores,\n",
    "    'obj_boxes':pred_obj_boxes,\n",
    "    'obj_classes':pred_obj_classes,\n",
    "    'human_scores':pred_human_scores, \n",
    "    'human_boxes':pred_human_boxes, \n",
    "    'human_classes':pred_human_classes\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet_test_data = pd.DataFrame({\n",
    "    'obj_scores':test_obj_scores,\n",
    "    'obj_boxes':test_obj_boxes,\n",
    "    'obj_classes':test_obj_classes,\n",
    "    'human_scores':test_human_scores, \n",
    "    'human_boxes':test_human_boxes, \n",
    "    'human_classes':test_human_classes\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet_train_data.human_boxes = [np.array(item) for item in retinanet_train_data.human_boxes.tolist()]\n",
    "retinanet_train_data.obj_boxes = [np.array(item) for item in retinanet_train_data.obj_boxes.tolist()]\n",
    "retinanet_test_data.human_boxes = [np.array(item) for item in retinanet_test_data.human_boxes.tolist()]\n",
    "retinanet_test_data.obj_boxes = [np.array(item) for item in retinanet_test_data.obj_boxes.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x1, y1, x2, y2)\n",
    "human_boxes_scale = []\n",
    "obj_boxes_scale = []\n",
    "for id_ in tqdm(range(len(retinanet_train_data))):\n",
    "    target_width = 1200\n",
    "    target_height = 800\n",
    "    scale_width = target_width/train_data_simple['size'][id_][0]\n",
    "    scale_height = target_height/train_data_simple['size'][id_][1]\n",
    "    if retinanet_train_data['human_boxes'][id_].any():\n",
    "        human_bbox = np.array([retinanet_train_data['human_boxes'][id_][:,0]/scale_width,retinanet_train_data['human_boxes'][id_][:,1]/scale_height,\n",
    "                               retinanet_train_data['human_boxes'][id_][:,2]/scale_width,retinanet_train_data['human_boxes'][id_][:,3]/scale_height]).astype('int64')\n",
    "    else:\n",
    "        human_bbox = np.array([])\n",
    "    if retinanet_train_data['obj_boxes'][id_].any():\n",
    "        object_bbox = np.array([retinanet_train_data['obj_boxes'][id_][:,0]/scale_width,retinanet_train_data['obj_boxes'][id_][:,1]/scale_height,\n",
    "                            retinanet_train_data['obj_boxes'][id_][:,2]/scale_width,retinanet_train_data['obj_boxes'][id_][:,3]/scale_height]).astype('int64')\n",
    "    else:\n",
    "        object_bbox = np.array([])\n",
    "    human_bbox = np.transpose(human_bbox)\n",
    "    object_bbox = np.transpose(object_bbox)\n",
    "    human_boxes_scale.append(human_bbox)\n",
    "    obj_boxes_scale.append(object_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet_train_data['human_boxes_scale'] = human_boxes_scale\n",
    "retinanet_train_data['obj_boxes_scale'] = obj_boxes_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x1, y1, x2, y2)\n",
    "human_boxes_scale = []\n",
    "obj_boxes_scale = []\n",
    "for id_ in tqdm(range(len(retinanet_test_data))):\n",
    "    target_width = 1200\n",
    "    target_height = 800\n",
    "    scale_width = target_width/test_data['size'][id_][0]\n",
    "    scale_height = target_height/test_data['size'][id_][1]\n",
    "    if retinanet_test_data['human_boxes'][id_].any():\n",
    "        human_bbox = np.array([retinanet_test_data['human_boxes'][id_][:,0]/scale_width,retinanet_test_data['human_boxes'][id_][:,1]/scale_height,\n",
    "                               retinanet_test_data['human_boxes'][id_][:,2]/scale_width,retinanet_test_data['human_boxes'][id_][:,3]/scale_height]).astype('int64')\n",
    "    else:\n",
    "        human_bbox = np.array([])\n",
    "    if retinanet_test_data['obj_boxes'][id_].any():\n",
    "        object_bbox = np.array([retinanet_test_data['obj_boxes'][id_][:,0]/scale_width,retinanet_test_data['obj_boxes'][id_][:,1]/scale_height,\n",
    "                            retinanet_test_data['obj_boxes'][id_][:,2]/scale_width,retinanet_test_data['obj_boxes'][id_][:,3]/scale_height]).astype('int64')\n",
    "    else:\n",
    "        object_bbox = np.array([])\n",
    "    human_bbox = np.transpose(human_bbox)\n",
    "    object_bbox = np.transpose(object_bbox)\n",
    "    human_boxes_scale.append(human_bbox)\n",
    "    obj_boxes_scale.append(object_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet_test_data['human_boxes_scale'] = human_boxes_scale\n",
    "retinanet_test_data['obj_boxes_scale'] = obj_boxes_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet_train_data.to_json('retinanet_train_data.json')\n",
    "retinanet_test_data.to_json('retinanet_test_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
