{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "# from keras_retinanet.models.resnet import custom_objects\n",
    "from keras_retinanet.models.resnet import resnet_retinanet as retinanet, custom_objects, download_imagenet\n",
    "# import keras_retinanet\n",
    "import keras_retinanet.bin.train\n",
    "from sklearn.utils import shuffle \n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_json('../train_data_simple.json')\n",
    "train_data = train_data.sort_index()\n",
    "retinanet_data = pd.read_json('retinanet_data.json')\n",
    "retinanet_data = retinanet_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26561, 7), (26561, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,retinanet_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_boxes</th>\n",
       "      <th>human_boxes_scale</th>\n",
       "      <th>human_classes</th>\n",
       "      <th>human_scores</th>\n",
       "      <th>obj_boxes</th>\n",
       "      <th>obj_boxes_scale</th>\n",
       "      <th>obj_classes</th>\n",
       "      <th>obj_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[408.5285644531, 137.1702575684, 590.03033447...</td>\n",
       "      <td>[[217, 82, 314, 289], [189, 108, 388, 279], [2...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.24128636720000002, 0.2087177634, 0.35492742...</td>\n",
       "      <td>[[384.8578491211, 70.9428253174, 883.437683105...</td>\n",
       "      <td>[[205, 42, 471, 217], [217, 82, 314, 289], [16...</td>\n",
       "      <td>[3, 0, 3, 3, 3, 0, 0, 0, 3]</td>\n",
       "      <td>[0.2452710122, 0.24128636720000002, 0.49595344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[515.2573242188, 2.3874969482, 1107.571899414...</td>\n",
       "      <td>[[274, 1, 590, 126], [401, 0, 636, 140]]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[0.34479168060000004, 0.6770228148]</td>\n",
       "      <td>[[756.3471679688, 567.7899169922, 817.62744140...</td>\n",
       "      <td>[[403, 340, 436, 363], [405, 341, 436, 363], [...</td>\n",
       "      <td>[49, 51, 51, 39, 41, 39, 55, 53, 45, 41, 45, 7...</td>\n",
       "      <td>[0.2125296295, 0.235072419, 0.2925423980000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>[[274, 401], [1, 0], [590, 636], [126, 140]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[295.9039916992, 352.1661376953, 341.69757080...</td>\n",
       "      <td>[[147, 281, 170, 341], [0, 361, 15, 388], [0, ...</td>\n",
       "      <td>[9, 2, 2, 2, 2, 2, 2, 2, 2, 7, 5, 5, 5]</td>\n",
       "      <td>[0.45125731830000004, 0.2788699865, 0.64107280...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[939.8218383789, 401.7608642578, 984.80657958...</td>\n",
       "      <td>[[501, 214, 525, 277], [130, 203, 165, 311], [...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.6018131971, 0.2301999032, 0.3746683598, 0.9...</td>\n",
       "      <td>[[939.8218383789, 401.7608642578, 984.80657958...</td>\n",
       "      <td>[[501, 214, 525, 277], [130, 203, 165, 311], [...</td>\n",
       "      <td>[0, 0, 27, 0, 0, 0, 0]</td>\n",
       "      <td>[0.6018131971, 0.2301999032, 0.2251143306, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[192.0525970459, 291.7764892578, 370.51116943...</td>\n",
       "      <td>[[102, 155, 197, 265]]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.9221789241]</td>\n",
       "      <td>[[321.814666748, 445.8058776855, 350.372467041...</td>\n",
       "      <td>[[171, 236, 186, 261], [532, 275, 554, 292], [...</td>\n",
       "      <td>[41, 67, 39, 0, 62, 59, 60, 60, 13, 60, 59]</td>\n",
       "      <td>[0.21376061440000002, 0.2884043753, 0.73071849...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         human_boxes  \\\n",
       "0  [[408.5285644531, 137.1702575684, 590.03033447...   \n",
       "1  [[515.2573242188, 2.3874969482, 1107.571899414...   \n",
       "2                                                 []   \n",
       "3  [[939.8218383789, 401.7608642578, 984.80657958...   \n",
       "4  [[192.0525970459, 291.7764892578, 370.51116943...   \n",
       "\n",
       "                                   human_boxes_scale       human_classes  \\\n",
       "0  [[217, 82, 314, 289], [189, 108, 388, 279], [2...        [0, 0, 0, 0]   \n",
       "1           [[274, 1, 590, 126], [401, 0, 636, 140]]              [0, 0]   \n",
       "2       [[274, 401], [1, 0], [590, 636], [126, 140]]                  []   \n",
       "3  [[501, 214, 525, 277], [130, 203, 165, 311], [...  [0, 0, 0, 0, 0, 0]   \n",
       "4                             [[102, 155, 197, 265]]                 [0]   \n",
       "\n",
       "                                        human_scores  \\\n",
       "0  [0.24128636720000002, 0.2087177634, 0.35492742...   \n",
       "1                [0.34479168060000004, 0.6770228148]   \n",
       "2                                                 []   \n",
       "3  [0.6018131971, 0.2301999032, 0.3746683598, 0.9...   \n",
       "4                                     [0.9221789241]   \n",
       "\n",
       "                                           obj_boxes  \\\n",
       "0  [[384.8578491211, 70.9428253174, 883.437683105...   \n",
       "1  [[756.3471679688, 567.7899169922, 817.62744140...   \n",
       "2  [[295.9039916992, 352.1661376953, 341.69757080...   \n",
       "3  [[939.8218383789, 401.7608642578, 984.80657958...   \n",
       "4  [[321.814666748, 445.8058776855, 350.372467041...   \n",
       "\n",
       "                                     obj_boxes_scale  \\\n",
       "0  [[205, 42, 471, 217], [217, 82, 314, 289], [16...   \n",
       "1  [[403, 340, 436, 363], [405, 341, 436, 363], [...   \n",
       "2  [[147, 281, 170, 341], [0, 361, 15, 388], [0, ...   \n",
       "3  [[501, 214, 525, 277], [130, 203, 165, 311], [...   \n",
       "4  [[171, 236, 186, 261], [532, 275, 554, 292], [...   \n",
       "\n",
       "                                         obj_classes  \\\n",
       "0                        [3, 0, 3, 3, 3, 0, 0, 0, 3]   \n",
       "1  [49, 51, 51, 39, 41, 39, 55, 53, 45, 41, 45, 7...   \n",
       "2            [9, 2, 2, 2, 2, 2, 2, 2, 2, 7, 5, 5, 5]   \n",
       "3                             [0, 0, 27, 0, 0, 0, 0]   \n",
       "4        [41, 67, 39, 0, 62, 59, 60, 60, 13, 60, 59]   \n",
       "\n",
       "                                          obj_scores  \n",
       "0  [0.2452710122, 0.24128636720000002, 0.49595344...  \n",
       "1  [0.2125296295, 0.235072419, 0.2925423980000000...  \n",
       "2  [0.45125731830000004, 0.2788699865, 0.64107280...  \n",
       "3  [0.6018131971, 0.2301999032, 0.2251143306, 0.3...  \n",
       "4  [0.21376061440000002, 0.2884043753, 0.73071849...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retinanet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = []\n",
    "image_name = []\n",
    "for id_ in range(len(train_data)):\n",
    "    image_name.append(os.path.join('/home/jovyan/projectdata/cht01/hico_20160224_det/images/train2015/',train_data['name'][id_]))\n",
    "    action_array = np.zeros(600)\n",
    "    for i in train_data.action_no[id_]:\n",
    "        action_array[i-1]=1\n",
    "    action_list.append(action_array)\n",
    "action_list = np.array(action_list)\n",
    "image_name = np.array(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_gt = [[item[0],item[2],item[1],item[3]] for item in train_data.human_bbox.tolist()]\n",
    "human_gt = np.array(human_gt)\n",
    "object_gt = [[item[0],item[2],item[1],item[3]] for item in train_data.object_bbox.tolist()]\n",
    "object_gt = np.array(object_gt)\n",
    "obj_label_gt = train_data.obj_id.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_input,obj_boxes,obj_classes,human_boxes\n",
    "obj_boxes,obj_boxes_scale,human_boxes,human_boxes_scale,obj_classes=[],[],[],[],[]\n",
    "for id_ in range(len(train_data)):\n",
    "    obj_box = retinanet_data.obj_boxes[id_]\n",
    "    obj_box_scale = retinanet_data.obj_boxes_scale[id_]\n",
    "    obj_class = retinanet_data.obj_classes[id_]\n",
    "    human_box = retinanet_data.human_boxes[id_]\n",
    "    human_box_scale = retinanet_data.human_boxes_scale[id_]\n",
    "\n",
    "    obj_box = np.array(obj_box)\n",
    "    obj_box_scale = np.array(obj_box_scale)\n",
    "    obj_class = np.array(obj_class)\n",
    "    human_box = np.array(human_box)\n",
    "    human_box_scale = np.array(human_box_scale)\n",
    "    \n",
    "    obj_boxes.append(obj_box)\n",
    "    obj_boxes_scale.append(obj_box_scale)\n",
    "    obj_classes.append(obj_class)\n",
    "    human_boxes.append(human_box)\n",
    "    human_boxes_scale.append(human_box_scale)\n",
    "    \n",
    "obj_boxes = np.array(obj_boxes)\n",
    "obj_boxes_scale = np.array(obj_boxes_scale)\n",
    "obj_classes = np.array(obj_classes)\n",
    "human_boxes = np.array(human_boxes)\n",
    "human_boxes_scale = np.array(human_boxes_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_train,image_name_val = sklearn.model_selection.train_test_split(image_name,test_size=0.05,random_state=42)\n",
    "\n",
    "human_boxes_train,human_boxes_val = sklearn.model_selection.train_test_split(human_boxes,test_size=0.05,random_state=42)\n",
    "\n",
    "human_boxes_scale_train,human_boxes_scale_val = sklearn.model_selection.train_test_split(human_boxes_scale,test_size=0.05,random_state=42)\n",
    "\n",
    "obj_boxes_train,obj_boxes_val = sklearn.model_selection.train_test_split(obj_boxes,test_size=0.05,random_state=42)\n",
    "\n",
    "obj_boxes_scale_train,obj_boxes_scale_val = sklearn.model_selection.train_test_split(obj_boxes_scale,test_size=0.05,random_state=42)\n",
    "\n",
    "obj_classes_train,obj_classes_val = sklearn.model_selection.train_test_split(obj_classes,test_size=0.05,random_state=42)\n",
    "\n",
    "action_list_train,action_list_val = sklearn.model_selection.train_test_split(action_list,test_size=0.05,random_state=42)\n",
    "\n",
    "human_gt_train,human_gt_val = sklearn.model_selection.train_test_split(human_gt,test_size=0.05,random_state=42)\n",
    "\n",
    "object_gt_train,object_gt_val = sklearn.model_selection.train_test_split(object_gt,test_size=0.05,random_state=42)\n",
    "\n",
    "obj_label_gt_train,obj_label_gt_val = sklearn.model_selection.train_test_split(obj_label_gt,test_size=0.05,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [image_name_train,human_boxes_train,human_boxes_scale_train,obj_boxes_train,obj_boxes_scale_train,obj_classes_train]\n",
    "\n",
    "x_val = [image_name_val,human_boxes_val,human_boxes_scale_val,obj_boxes_val,obj_boxes_scale_val,obj_classes_val]\n",
    "\n",
    "y_train = [action_list_train,human_gt_train,object_gt_train,obj_label_gt_train]\n",
    "\n",
    "y_val = [action_list_val,human_gt_val,object_gt_val,obj_label_gt_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_stream(ip):\n",
    "    human_boxes = ip[0]\n",
    "    human_boxes = human_boxes[0,:,:]\n",
    "    img_input = ip[1]\n",
    "    crop_size = K.tf.constant([400,400])\n",
    "    batch_inds = K.tf.zeros((K.tf.shape(human_boxes)[0],), dtype=K.tf.int32) \n",
    "    human_boxes_norm = human_boxes/[1200,800,1200,800]\n",
    "    human_boxes_norm = K.tf.stack([human_boxes_norm[:,1],human_boxes_norm[:,0],human_boxes_norm[:,3],human_boxes_norm[:,2]],axis=1)\n",
    "\n",
    "    result = K.tf.image.crop_and_resize(img_input,human_boxes_norm,batch_inds,crop_size)\n",
    "\n",
    "    result = (result-K.min(result))/255 \n",
    "    return [result,human_boxes_norm]\n",
    "    \n",
    "def obj_stream(ip):\n",
    "    obj_boxes = ip[0]\n",
    "    obj_boxes = obj_boxes[0,:,:]\n",
    "    img_input = ip[1]\n",
    "    crop_size = K.tf.constant([400,400])\n",
    "    batch_inds = K.tf.zeros((K.tf.shape(obj_boxes)[0],), dtype=K.tf.int32) \n",
    "    obj_boxes_norm = obj_boxes/[1200,800,1200,800]\n",
    "    obj_boxes_norm = K.tf.stack([obj_boxes_norm[:,1],obj_boxes_norm[:,0],obj_boxes_norm[:,3],obj_boxes_norm[:,2]],axis=1)\n",
    "    result = K.tf.image.crop_and_resize(img_input,obj_boxes_norm,batch_inds,crop_size)\n",
    "    result = (result-K.min(result))/255 \n",
    "\n",
    "    return [result,obj_boxes_norm]\n",
    "\n",
    "def human_object_pair(ip):\n",
    "    human_boxes=ip[0]\n",
    "    obj_boxes=ip[1]\n",
    "    human_boxes = human_boxes[0,:,:]\n",
    "    obj_boxes = obj_boxes[0,:,:]\n",
    "    human_boxes_norm=ip[2]\n",
    "    obj_boxes_norm=ip[3]\n",
    "    human_count =K.tf.shape(human_boxes)[0]\n",
    "    obj_count = K.tf.shape(obj_boxes)[0]\n",
    "    ho_pair=[]\n",
    "    xx = K.tf.expand_dims(human_boxes, -1)\n",
    "    xx = K.tf.tile(xx, K.tf.stack([1, 1, obj_count]))\n",
    "    yy = K.tf.expand_dims(obj_boxes, -1)\n",
    "    yy = K.tf.tile(yy, K.tf.stack([1, 1, human_count]))\n",
    "    yy = K.tf.transpose(yy, perm=[2, 1, 0])       \n",
    "    ho_pair = K.tf.stack([xx,yy],axis=1)\n",
    "    ho_pair = K.tf.transpose(ho_pair,perm=[0,3,1,2])\n",
    "    ho_pair = K.tf.reshape(ho_pair,shape=(-1,2,4))\n",
    "    ho_pair_norm=[]\n",
    "    xx_norm = K.tf.expand_dims(human_boxes_norm, -1)\n",
    "    xx_norm = K.tf.tile(xx_norm, K.tf.stack([1, 1, obj_count]))\n",
    "    yy_norm = K.tf.expand_dims(obj_boxes_norm, -1)\n",
    "    yy_norm = K.tf.tile(yy_norm, K.tf.stack([1, 1, human_count]))\n",
    "    yy_norm = K.tf.transpose(yy_norm, perm=[2, 1, 0])       \n",
    "    ho_pair_norm = K.tf.stack([xx_norm,yy_norm],axis=1)\n",
    "    ho_pair_norm = K.tf.transpose(ho_pair_norm,perm=[0,3,1,2])\n",
    "    ho_pair_norm = K.tf.reshape(ho_pair_norm,shape=(-1,2,4))\n",
    "    return ho_pair\n",
    "\n",
    "def attention_pattern(ho_pair):\n",
    "    pair_count = K.tf.shape(ho_pair)[0]\n",
    "    offset_height_h = K.tf.cast(ho_pair[:,0,1],K.tf.int32)\n",
    "    offset_width_h = K.tf.cast(ho_pair[:,0,0],K.tf.int32)\n",
    "    target_height_h = K.tf.cast(ho_pair[:,0,3],K.tf.int32) - offset_height_h \n",
    "    target_width_h = K.tf.cast(ho_pair[:,0,2],K.tf.int32) - offset_width_h\n",
    "    offset_height_o = K.tf.cast(ho_pair[:,1,1],K.tf.int32)\n",
    "    offset_width_o = K.tf.cast(ho_pair[:,1,0],K.tf.int32)\n",
    "    target_height_o = K.tf.cast(ho_pair[:,1,3],K.tf.int32) - offset_height_o\n",
    "    target_width_o = K.tf.cast(ho_pair[:,1,2],K.tf.int32) -offset_width_o\n",
    "    mask_base = K.tf.constant(1,shape=(800,1200,3),dtype=K.tf.float32)\n",
    "    i = K.tf.constant(0)\n",
    "    pair_mask = K.tf.TensorArray(dtype=K.tf.float32, size=pair_count)\n",
    "    def condition(i,pair_mask):\n",
    "        return i < pair_count\n",
    "    \n",
    "    def body(i,pair_mask):\n",
    "        top_bound = K.tf.reduce_min(K.tf.stack([offset_height_h[i],offset_height_o[i]]))\n",
    "        left_bound = K.tf.reduce_min(K.tf.stack([offset_width_h[i],offset_width_o[i]]))\n",
    "        bottom_bound = K.tf.reduce_max(K.tf.stack([offset_height_h[i]+target_height_h[i],offset_height_o[i]+target_height_o[i]]))\n",
    "        right_bound = K.tf.reduce_max(K.tf.stack([offset_width_h[i]+target_width_h[i],offset_width_o[i]+target_width_o[i]]))\n",
    "        mask_target_height = bottom_bound-top_bound\n",
    "        mask_target_width = right_bound-left_bound\n",
    "        mask_h = K.tf.image.crop_to_bounding_box(\n",
    "            mask_base,offset_height_h[i],offset_width_h[i],target_height_h[i],target_width_h[i])\n",
    "        mask_h = K.tf.image.pad_to_bounding_box(mask_h,offset_height_h[i]-top_bound,offset_width_h[i]-left_bound,mask_target_height,mask_target_width)\n",
    "        mask_h = K.tf.image.resize_image_with_crop_or_pad(mask_h,K.tf.shape(mask_base)[0],K.tf.shape(mask_base)[1])\n",
    "        mask_o = K.tf.image.crop_to_bounding_box(\n",
    "            mask_base,offset_height_o[i],offset_width_o[i],target_height_o[i],target_width_o[i])\n",
    "        mask_o = K.tf.image.pad_to_bounding_box(mask_o,offset_height_o[i]-top_bound,offset_width_o[i]-left_bound,mask_target_height,mask_target_width)\n",
    "        mask_o = K.tf.image.resize_image_with_crop_or_pad(mask_o,K.tf.shape(mask_base)[0],K.tf.shape(mask_base)[1])\n",
    "        mask_combine = [K.tf.reduce_mean(mask_h,axis=2),K.tf.reduce_mean(mask_o,axis=2),K.tf.constant(0,shape=(800,1200),dtype=K.tf.float32)]\n",
    "        mask_combine = K.tf.stack(mask_combine,axis =2)\n",
    "        mask_combine = K.tf.expand_dims(mask_combine,axis=0)\n",
    "        mask_combine = K.tf.image.resize_bilinear(mask_combine,[128,128])\n",
    "        mask_combine = K.tf.squeeze(mask_combine,axis=0)\n",
    "        pair_mask = pair_mask.write(i, mask_combine)\n",
    "        i = K.tf.add(i,1)\n",
    "        return [i, pair_mask]\n",
    "    n, pair_mask = K.tf.while_loop(condition, body, [i, pair_mask])\n",
    "    # get the final result\n",
    "    pair_mask_stack = pair_mask.stack()\n",
    "    return pair_mask_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = keras.layers.Input(shape=(None,None,3),name='img_input')\n",
    "obj_boxes = keras.layers.Input(shape=(None,4),name='obj_boxes')\n",
    "obj_classes = keras.layers.Input(shape=(None,),name='obj_classes')\n",
    "human_boxes = keras.layers.Input(shape=(None,4),name='human_boxes')\n",
    "\n",
    "human_subimage,human_boxes_norm = keras.layers.Lambda(human_stream)([human_boxes,img_input])\n",
    "\n",
    "obj_subimage,obj_boxes_norm = keras.layers.Lambda(obj_stream)([obj_boxes,img_input])\n",
    "\n",
    "ho_pair= keras.layers.Lambda(human_object_pair)([human_boxes,obj_boxes,human_boxes_norm,obj_boxes_norm])\n",
    "\n",
    "pair_mask_stack = keras.layers.Lambda(attention_pattern)(ho_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dim(ip):\n",
    "    human_subimage = ip[0]\n",
    "    object_subimage = ip[1]\n",
    "    pair_mask_stack = ip[2]\n",
    "    human_subimage_expand = K.tf.expand_dims(human_subimage,axis=0)\n",
    "    obj_subimage_expand = K.tf.expand_dims(obj_subimage,axis=0)\n",
    "    pair_mask_stack_expand = K.tf.expand_dims(pair_mask_stack,axis=0)\n",
    "    return [human_subimage_expand,obj_subimage_expand,pair_mask_stack_expand]\n",
    "def output_sum(score_600):\n",
    "    score_sum = K.tf.reduce_sum(score_600,axis=1)\n",
    "    return score_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_subimage_expand,obj_subimage_expand,pair_mask_stack_expand= keras.layers.Lambda(expand_dim)([human_subimage,obj_subimage,pair_mask_stack])\n",
    "# #human stream\n",
    "# h_conv1 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(human_subimage_expand)\n",
    "# h_pool1 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(h_conv1)\n",
    "# h_conv2 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(h_pool1)\n",
    "# h_pool2 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(h_conv2)\n",
    "# h_conv3 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(h_pool2)\n",
    "# h_pool3 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(h_conv3)\n",
    "# h_flat = keras.layers.TimeDistributed(keras.layers.Flatten())(h_pool3)\n",
    "# h_output = keras.layers.TimeDistributed(keras.layers.Dense(units=600,activation='sigmoid'))(h_flat)\n",
    "# #object stream\n",
    "# o_conv1 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(obj_subimage_expand)\n",
    "# o_pool1 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(o_conv1)\n",
    "# o_conv2 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(o_pool1)\n",
    "# o_pool2 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(o_conv2)\n",
    "# o_conv3 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(o_pool2)\n",
    "# o_pool3 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(3,3)))(o_conv3)\n",
    "# o_flat = keras.layers.TimeDistributed(keras.layers.Flatten())(o_pool3)\n",
    "# o_output = keras.layers.TimeDistributed(keras.layers.Dense(units=600,activation='sigmoid'))(o_flat)\n",
    "# #pairwise stream\n",
    "# p_conv1 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(pair_mask_stack_expand)\n",
    "# p_pool1 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(2,2)))(p_conv1)\n",
    "# p_conv2 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(p_pool1)\n",
    "# p_pool2 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(2,2)))(p_conv2)\n",
    "# p_conv3 = keras.layers.TimeDistributed(keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu'))(p_pool2)\n",
    "# p_pool3 = keras.layers.TimeDistributed(keras.layers.MaxPool2D(pool_size=(2,2)))(p_conv3)\n",
    "# p_flat = keras.layers.TimeDistributed(keras.layers.Flatten())(p_pool3)\n",
    "# p_output = keras.layers.TimeDistributed(keras.layers.Dense(units=600,activation='sigmoid'))(p_flat)\n",
    "\n",
    "# # score_sum = keras.layers.Add()([h_output_merge,o_output_merge,p_output_merge])\n",
    "# # score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)\n",
    "# score_sum = keras.layers.Add()([h_output,o_output,p_output])\n",
    "# score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_subimage_expand,obj_subimage_expand,pair_mask_stack_expand= keras.layers.Lambda(expand_dim)([human_subimage,obj_subimage,pair_mask_stack])\n",
    "#human stream\n",
    "h_conv1 = keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(human_subimage)\n",
    "h_pool1 = keras.layers.MaxPool2D(pool_size=(3,3))(h_conv1)\n",
    "h_conv2 = keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(h_pool1)\n",
    "h_pool2 = keras.layers.MaxPool2D(pool_size=(3,3))(h_conv2)\n",
    "h_conv3 = keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(h_pool2)\n",
    "h_pool3 = keras.layers.MaxPool2D(pool_size=(3,3))(h_conv3)\n",
    "h_flat = keras.layers.Flatten()(h_pool3)\n",
    "h_output = keras.layers.Dense(units=600,activation='sigmoid')(h_flat)\n",
    "#object stream\n",
    "o_conv1 = keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(obj_subimage)\n",
    "o_pool1 = keras.layers.MaxPool2D(pool_size=(3,3))(o_conv1)\n",
    "o_conv2 = keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(o_pool1)\n",
    "o_pool2 = keras.layers.MaxPool2D(pool_size=(3,3))(o_conv2)\n",
    "o_conv3 = keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(o_pool2)\n",
    "o_pool3 = keras.layers.MaxPool2D(pool_size=(3,3))(o_conv3)\n",
    "o_flat = keras.layers.Flatten()(o_pool3)\n",
    "o_output = keras.layers.Dense(units=600,activation='sigmoid')(o_flat)\n",
    "#pairwise stream\n",
    "p_conv1 = keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(pair_mask_stack)\n",
    "p_pool1 = keras.layers.MaxPool2D(pool_size=(2,2))(p_conv1)\n",
    "p_conv2 = keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(p_pool1)\n",
    "p_pool2 = keras.layers.MaxPool2D(pool_size=(2,2))(p_conv2)\n",
    "p_conv3 = keras.layers.Conv2D(filters=64,kernel_size=(3,3),strides=(1, 1), padding='same',activation='relu')(p_pool2)\n",
    "p_pool3 = keras.layers.MaxPool2D(pool_size=(2,2))(p_conv3)\n",
    "p_flat = keras.layers.Flatten()(p_pool3)\n",
    "p_output = keras.layers.Dense(units=600,activation='sigmoid')(p_flat)\n",
    "\n",
    "# score_sum = keras.layers.Add()([h_output_merge,o_output_merge,p_output_merge])\n",
    "# score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)\n",
    "score_sum = keras.layers.Add()([h_output,o_output,p_output])\n",
    "score_sum_sigmoid = keras.layers.Dense(600,activation='sigmoid')(score_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[img_input,human_boxes,obj_boxes,obj_classes],outputs=[score_sum_sigmoid,obj_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "human_boxes (InputLayer)        (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "img_input (InputLayer)          (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "obj_boxes (InputLayer)          (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 400, 400, 3) 0           human_boxes[0][0]                \n",
      "                                                                 img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               [(None, 400, 400, 3) 0           obj_boxes[0][0]                  \n",
      "                                                                 img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2, 4)         0           human_boxes[0][0]                \n",
      "                                                                 obj_boxes[0][0]                  \n",
      "                                                                 lambda_1[0][1]                   \n",
      "                                                                 lambda_2[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 3)  0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 400, 400, 16) 448         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 400, 400, 16) 448         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 16) 448         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 133, 133, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 133, 133, 16) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 16)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 133, 133, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 133, 133, 32) 4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 44, 44, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 44, 44, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 44, 44, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 44, 44, 64)   18496       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12544)        0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 12544)        0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 16384)        0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 600)          7527000     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 600)          7527000     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 600)          9831000     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 600)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 600)          360600      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "obj_classes (InputLayer)        (None, None)         0                                            \n",
      "==================================================================================================\n",
      "Total params: 25,316,352\n",
      "Trainable params: 25,316,352\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    y_true = y_true[0]\n",
    "    y_pred = y_pred[0]\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "# def binary_accuracy(y_true, y_pred):\n",
    "#     y_true = y_true[0]\n",
    "#     y_pred = y_pred[0]\n",
    "#     return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss=custom_loss,\n",
    "              optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = [image_name,human_boxes,obj_boxes,obj_classes]  y_label = [action_list,human_gt,object_gt]\n",
    "# (x1, y1, x2, y2)\n",
    "def bb_intersection_over_union(boxA,boxB):\n",
    "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
    "\txA = max(boxA[0], boxB[0])\n",
    "\tyA = max(boxA[1], boxB[1])\n",
    "\txB = min(boxA[2], boxB[2])\n",
    "\tyB = min(boxA[3], boxB[3])\n",
    " \n",
    "\t# compute the area of intersection rectangle\n",
    "\tinterArea = (xB - xA + 1) * (yB - yA + 1)\n",
    " \n",
    "\t# compute the area of both the prediction and ground-truth\n",
    "\t# rectangles\n",
    "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    " \n",
    "\t# compute the intersection over union by taking the intersection\n",
    "\t# area and dividing it by the sum of prediction + ground-truth\n",
    "\t# areas - the interesection area\n",
    "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "\t# return the intersection over union value\n",
    "\treturn iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = [image_name_train, human_boxes_train, human_boxes_scale_train, obj_boxes_train, obj_boxes_scale_train, obj_classes_train]\n",
    "# x_val = [image_name_val,human_boxes_val,human_boxes_scale_val,obj_boxes_val,obj_boxes_scale_val,obj_classes_val]\n",
    "# y_train = [action_list_train, human_gt_train, object_gt_train, obj_label_gt_train]\n",
    "# y_val = [action_list_val,human_gt_val,object_gt_val,obj_label_gt_val]\n",
    "def data_gen(x_train, y_label,batch_size=8):\n",
    "    img_stack = np.array([]).reshape(0,800,1200,3)\n",
    "    action_array_stack = np.array([]).reshape(0,600)\n",
    "    human_stack = np.array([]).reshape(0,1,4)\n",
    "    object_stack = np.array([]).reshape(0,1,4)\n",
    "    object_class_stack = np.array([]).reshape(0,1)\n",
    "    while True:\n",
    "        new_ind = shuffle(range(len(x_train[0])))\n",
    "        for i in new_ind:\n",
    "            if (x_train[1][i].any()) & (x_train[3][i].any()) &(y_label[3][i][0] in x_train[5][i]):\n",
    "                \n",
    "                human_iou_list = []\n",
    "                for k in x_train[2][i]:\n",
    "                    human_iou_list.append(bb_intersection_over_union(y_label[1][i],k))\n",
    "                object_iou_list = []\n",
    "                for j in x_train[4][i]:\n",
    "                    object_iou_list.append(bb_intersection_over_union(y_label[1][i],j))\n",
    "                \n",
    "                ho_pair_h = x_train[1][i][np.argmax(human_iou_list)]\n",
    "                ho_pair_o = x_train[3][i][np.argmax((x_train[5][i]==y_label[3][i][0])*object_iou_list)]\n",
    "                ho_pair_h = np.expand_dims(ho_pair_h,axis=0)\n",
    "                ho_pair_h = np.expand_dims(ho_pair_h,axis=0)\n",
    "                ho_pair_o = np.expand_dims(ho_pair_o,axis=0)\n",
    "                ho_pair_o = np.expand_dims(ho_pair_o,axis=0)\n",
    "\n",
    "                object_class = x_train[5][i][np.argmax((x_train[5][i]==y_label[3][i][0])*object_iou_list)]\n",
    "                object_class = np.expand_dims(object_class,axis=0)\n",
    "                \n",
    "                img = cv2.imread(x_train[0][i])\n",
    "                img = cv2.resize(img, (1200,800))\n",
    "                img = img/255\n",
    "                img = np.expand_dims(img,axis=0)\n",
    "                \n",
    "                \n",
    "                \n",
    "                img_stack = np.row_stack([img_stack,img])\n",
    "                action_array_stack = np.row_stack([action_array_stack,y_label[0][i]])\n",
    "                human_stack = np.row_stack([human_stack,ho_pair_h])\n",
    "                object_stack = np.row_stack([object_stack,ho_pair_o])\n",
    "                object_class_stack = np.row_stack([object_class_stack,object_class])\n",
    "                \n",
    "                if img_stack.shape[0]==batch_size:\n",
    "                    x_batch = [img_stack,human_stack,object_stack,object_class_stack]\n",
    "                    y_batch = [action_array_stack,object_class_stack]\n",
    "                    img_stack = np.array([]).reshape(0,800,1200,3)\n",
    "                    action_array_stack = np.array([]).reshape(0,600)\n",
    "                    human_stack = np.array([]).reshape(0,1,4)\n",
    "                    object_stack = np.array([]).reshape(0,1,4)\n",
    "                    object_class_stack = np.array([]).reshape(0,1)\n",
    "\n",
    "                    yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_gen(x_train,y_train)\n",
    "val_gen = data_gen(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25232, 1329)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0]),len(x_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b = next(val_gen)\n",
    "# a[0].shape,a[1].shape,a[2].shape,b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爆Train一發"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 36s 725ms/step - loss: -355.1244 - dense_4_loss: 0.0720 - obj_classes_loss: -355.1963 - val_loss: -653.6197 - val_dense_4_loss: 0.0181 - val_obj_classes_loss: -653.6378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05c07db780>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen,steps_per_epoch=50,epochs=1,validation_data=val_gen,validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"/home/jovyan/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('/home/jovyan/hico_first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/jovyan/hico_first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_gen = data_gen(x_train,y_train,batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = next(visualize_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_on_batch(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
